# 技术基础

## 何为技术领导力以及怎么做

人类社会的发展阶段
1. 野蛮开采。 这个阶段主要特点是资源过多，只需要开采就好了。
2. 资源整合。 在这个阶段，资源已经被不同的人给占有了，但是需要对资源整合优化，提高利用率。
3. 精耕细作。 这个阶段基本上是对第二阶段的精细化运作，并且通过科学的手段来达到。
4. 发明创造。 在这个阶段，人们利用已有不足的资源来创造更好的资源，并替代已有的马上要枯竭的资源。

什么是技术领导力：
- 尊重技术，追求核心基础技术。
- 追逐自动化的高效率的工具和技术，同时避免无效率的组织架构和管理。
- 解放生产力，追逐人效的提高。
- 开发抽象和高质量的可以重用的技术组件。
- 坚持高于社会主流的技术标准和要求。

怎样才算拥有“技术领导力” 呢
- 能够发现问题。 能够发现现有方案的问题。
- 能够提供解决问题的思路和方案，并能比较这些方案的优缺点。
- 能够做出正确的技术决定。 用什么样的技术、什么解决方案呢、怎样实现来完成一个项目。
- 能够用更优雅，更简单，更容易的方式来解决问题。
- 能够提高代码或软件的扩展性、重用性和可维护性。
- 能够用正确的方式管理团队。 一是让正确的人做正确的事，并发挥每个人的潜力； 另一方面是，
可以提高团队的生产力和人效，找到最优价值的需求，用最少的成本实现。 并且可以不断地提高自身和团队的标准。
- 创新能力。能够使用新的方式解决问题，追逐新的工具和技术。

技术基础提高具体分为编程和系统两部分。
1. 编程：
- C语言
- 编程范式
- 算法和数据结构
2. 系统：
- 计算机系统原理, CPU 的体系结构（指令集 [CISC/RISC]、分支预测、缓存结构、总线、DMA、中断、陷阱、多任务、虚拟内存、虚拟化等），内存的原理与性能特点（SRAM、DRAM、DDR-SDRAM 等），磁盘的原理（机械硬盘 [盘面、磁头臂、磁头、启停区、寻道等]、固态硬盘 [页映射、块的合并与回收算法、TRIM 指令等]），GPU 的原理等
- 操作系统原理和基础，进程、进程管理、线程、线程调度、多核的缓存一致性、信号量、物理内存管理、虚拟内存管理、内存分配、文件系统、磁盘管理等。
- 网络基础，需要了解基本的网络层次结构（ISO/OSI 模型、TCP/IP 协议栈），包括物理层、数据链路层（包含错误重发机制）、网络层（包含路由机制）、传输层（包含连接保持机制）、会话层、表示层、应用层（在 TCP/IP 协议栈里，这三层可以并为一层）。
- 数据库原理：数据库管理系统是管理数据库的利器。
- 分布式技术架构，包括负载均衡、DNS 解析、多子域名、无状态应用层、缓存层、数据库分片、容错和恢复机制、Paxos、Map/Reduce 操作、分布式 SQL 数据库一致性（以 Google Cloud Spanner 为代表）等知识点。

Google评分卡：
```
0 - you are unfamiliar with the subject area.
1 - you can read / understand the most fundamental aspects of the subject area.
2 - ability to implement small changes, understand basic principles and able to figure out additional details with minimal help.
3 - basic proficiency in a subjet area without relying on help.
4 - you are comfortable with the subject area and all routine work on it:
For software areas - ability to develop medium programs using all basic language features w/o book, awareness
of more esoteric features (with book).
For system areas - understanding of many fundadmentals of networking and systems administration, ability to run a small network of 
systems includin recovery, debugging and nontrivial troubleshooting that relies on the knowledge of internals.
5 - an even lower degreee of reliance on reference materials. Deeper skills in a field or specific technology in the subject area.
6 - ability to develop large programs and systems from scratch. Understanding of low level details and internals. Ability to desgn / deploy most large, distributed systems from scratch.
7 - you understand and make use of most lesser known language features, technologies, and associated internnals.
Ability to automate signifcant amounts of systems administration.
8 - deep understanding of corner cases, esoteric features, protocols and systems including "theory of operation". Demopnstrated ability to design, deploy and own very critical or large infrastructure, build accompanying automation.
9 - could have written the book about the subject area but didn't; works with standards committees on defining new standards and 
methodologies.
10 - wrote the book on the subject area(there actually has to be a book). Recognized industry expert in the field, might have invented it.
```

## 程序中的错误处理：错误返回码和异常捕捉

错误的分类：
1. 资源的错误。这一类错误属于程序运行环境的问题。对于这类错误，有的我们可以处理，有的我们则无法处理。比如，内存耗尽、栈溢出或是一些程序运行时关键性资源不能满足等等这些情况，我们能只能停止运行，甚至退出整个程序。
2. 程序的错误。比如：空指针、非法参数等。这类是自己程序的错误，要记录下来，写入日志，最好触发监控系统报警。
3. 用户的错误。基本是在用户的API层上出现的问题，对于这类问题，需要向用户端报错，让用户自己处理修正他们的输入或操作。然后，正常执行，但是需要做统计，统计相应的错误率，这样有利于改善软件或是侦测是否有恶意的用户请求。

错误处理的最佳实践：
1. 统一分类的错误字典。
2. 同类错误的定义最好是可以扩展的。
3. 定义错误的严重程度。
4. 错误日志的输出最好使用错误码，而不是错误信息。
5. 忽略错误最好有日志。
6. 对于同一个地方不停的报错，最好不要都打到日志里。最好的实践是打出一个错误以及出现的次数。
7. 不要用错误处理逻辑来处理业务逻辑。
8. 对于同类的错误处理，用一样的模式。
9. 尽可能在错误发生的地方处理错误。
10. 向上尽可能地返回原始的错误。
11. 处理错误时，总是要清理已分配的资源。
12. 不推荐在循环体里处理错误。
13. 不要把大量的代码都放在一个try语句块内。
14. 为错误定义提供清楚的文档以及每种错误的代码示例。
15. 对于异步的方式，推荐使用Promise模式处理错误。
16. 对于分布式的系统，推荐使用APM相关的软件。

## 机器学习

监督式学习算法：
1. 决策树（Decision Tree）。比如自动化放贷、风控。
2. 朴素贝叶斯分类（Naive Bayesan classification）。可以用于判断垃圾邮件，对新闻的类别进行分类，
比如科技、政治、运动，判断文本表达的感情是积极的还是消极的，以及人脸识别等。
3. 最小二乘法（Ordinary Least Squares Regresion）。算是一种线性回归。
4. 逻辑回归（Logistic Regression）。一种强大的统计学方法，可以用一个或多个变量来表示一个二项式结果。
它可以用于信用评分、计算营销活动的成功率、预测某个产品的收入等。
5. 支持向量机（Support Vector Machine，SVM）。可以用于基于图像的性别检测，图像分类等。
6. 集成方法（Ensemble methods）。通过构建一组分类器，然后根据它们的预测结果进行加权投票来对新的数据点进行
分类。原始的集成方法是贝叶斯平均，但是最近的算法包括纠错输出编码、Bagging和Boosting。

非监督式学习：
1. 聚类算法（Clustering Algorithms）。目标是给数据分类。
2. 主成分分析（Principal Component Analysis, PCA）。PCA的一些应用包括压缩、简化数据，便于学习和可视化等。
3. 奇异值分解（Singular Value Decompostion, SVD）。实际上，PCA是SVD的一个简单应用。在计算机视觉中，第一个
人脸识别算法使用PCA和SVD来将面部表示为“特征面”的线性组合，进行降维，然后通过简单的方法将面部匹配到身份。
4. 独立成分分析（Inpedendent Component Analysis, ICA）。ICA是一种统计技术，主要用于揭示随机变量、测量值或
信号集中的隐藏因素。 

## 时间管理

### 抗争不合理的时间占用
主动管理：主动管理的不是时间，而是管理同事，管理信息。

学会说不：
1. 面对做不到的需求时，不要说这个需求做不到。给出另一个可以做到的方案，而不是把对方的方案直接回绝掉。
2. 面对过于复杂的需求时，不要说不。不说不能完全满足，但说可以部分满足。
3. 面对时间完全不够的需求，不要说不。既然对方给到压力，要想办法把压力还回去，或是让对方一同分担这个压力。
“积极主动的态度对于不合理的事讨价还价”。

加班和开会：开会，不是讨论问题，而是讨论方案，开会不是要有议题，而是要有议案。

### 投资自己的时间

1. 花时间学习基础知识，花时间读文档。
2. 花时间在解放自己生产力的事上。在自动化、可配置、可重用、可扩展上要多花时间。
3. 花时间在让自己成长的事上。
4. 花时间在建立高效的环境上。

### 规划自己的时间

1. 定义好优先级
2. 最短作业优先
3. 想清楚再做
4. 关注长期利益规划
学会规划自己的行动计划，不是短期的，而是一个中长期的。按季度来规划，这个季度做什么，打到什么目标。

### 用好自己的时间

1. 学会过滤掉与自己目标无关的事。
2. 形成习惯。
3. 形成正反馈。
4. 反思和举一反三。

## 故障处理最佳实践

### 应对故障

故障发生时
1. 重启和限流。重启和限流主要解决的是可用性的问题，不是功能性问题。
2. 回滚操作。 回滚操作一般来说是解决新代码的bug，把代码回滚到之前的版本是快速的方式。
3. 降级操作。如果无法回滚，就需要降级功能，不要把事态扩大。
4. 紧急更新。 紧急更新是常用的手段，这个需要强大的自动化系统，尤其是自动化测试和自动化发布系统。
出现故障时，最重要的不是debug故障，而是尽可能地减少故障的影响范围，并尽可能快地修复问题。

故障前的准备工作
1. 以用户功能为索引的服务和资源的全视图。
2. 为地图中的各个服务制定关键指标，以及一套运维流程和工具，包括应急方案。以用户功能为索引，
为每个用户功能的服务都制定一个服务故障的检测、处理和恢复手册，以及相关的检测、查错或是恢复的运维工具。
3. 设定故障的等级。
4. 故障的演练。
5. 灰度发布系统。

### 故障改进

COE（Correction of Errors）文档，包括以下内容：
1. 故障处理的整个过程。就像一个log一样，需要详细地记录几点几分干了什么事，把故障从发生到解决的所有细节过程都记录下来。
2. 故障原因分析。需要说明故障的原因和分析报告。
3. Ask 5 Whys。需要反思并反问至少5个为什么，并为这些“为什么”找到答案。
4. 故障后续整改计划。需要针对上述的“Ask 5 Whys”说明后续如何举一反三地从根本上解决所有的问题。

惩罚故障责任人的方式不好之处：
1. 惩罚故障责任人对于解决故障完全没有任何帮助。因为它们之间没有因果关系，既不是充分条件，也不是必要条件，更不是充要条件。这是逻辑上的错误。
2. 做得越多，错得越多。如果不想出错，最好什么也不要做。所以，惩罚故障责任人只会让大家都很保守，也会让大家都学会保守，而且开始推诿，营造一种恐怖的气氛。

故障整改方法：
1. 优化故障获知和故障定位的时间。
- 从故障发生到我们知道的时间是否可以优化得更短？
- 定位故障得时间是否恶意更短？
- 有哪些地方可以做到自动化？
2. 优化故障的处理方式。
- 故障处理时的判断和章法是否科学，是否正确？
- 故障处理时的信息是否全透明？
- 故障处理时人员是否安排得当？
3. 优化开发过程中的问题。
- Code Review和测试中的问题和优化点。
- 软件架构和设计是否可以更好？
- 对于技术欠债或是相关的隐患问题是否被记录下来，是否有风险计划？
4. 优化团队能力。
- 如何提高团队的技术能力？
- 如何让团队有严谨的工程意识？

找到问题的本质：
1. 举一反三解决当下的故障。为自己赢得更多的时间。
2. 简化复杂、不合理的技术架构、流程和组织。不可能在一个复杂的环境下根本地解决问题。
3. 全面改善和优化整个系统，包括组织。解决问题的根本方法是改善和调整整体结构。而只有简单优雅的东西才有被改善和优化的可能。

## 应该识别的本质和表象

关于学习和工作
本质上来说，并不是只有找到了相应的工作我们才可以学好一项技术，而是，我们在通过解决实际问题，在和他人讨论，获得高手帮助的环境中，才能更快更有效率地学习和成长。
找工作不只是找用这个技术的工作，更是要找场景，找实际问题，找团队，这些才是本质。一项技术很多公司都在用，然而，只有进入到有更多的场景、有挑战性的问题、有靠谱团队的公司，才对学习和成长更有帮助。
不要完全把自己的学习寄希望于找一份工作，才会学得好。

关于技术和价值
技术无贵贱，很多伟大的事就是通过一些不起眼的技术造就的。所以我们应该关注的是：
- 要用技术解决什么样的问题，场景非常重要；
- 如何降低技术的学习成本，提高易用性，从而可以让技术更为普及。

一项有价值的技术，并不在于这项技术是否有技术含量，而是在于：
- 能否低成本高效率地解决实际问题；
- 是不是众多产品的基础技术；
- 是不是可以支持规模化的技术。

关于趋势和未来
这个世界的技术趋势和未来其实是被人控制的。就是被那些有权有势有钱的公司或国家来控制的。当然，他们控制的不是长期的未来，
但短期的未来（3-5年）一定是他们控制着的。

## Git协同工作流

中心式协同工作流
功能分支协同工作流
GitFlow协同工作流
GitHub/GitLab协同工作流
GitHub Flow
GitLab Flow

团队协同工作的本质不外乎几个事：
1. 不同的团队能够尽可能地并行开发。
2. 不同软件版本和代码的一致性。
3. 不同环境和代码的一致性。
4. 代码总是会在稳定和不稳定间交替。

与其花时间在Git协同工作流上，还不如把时间花在调整软件架构和自动化软件生产和运维流程上来，这才是真正简化协同工作流程的根本。

# 分布式架构

使用分布式系统的原因：
1. 增大系统容量。
2. 加强系统可用。

单体应用和分布式架构的优缺点
|     | 传统单体架构 | 分布式服务化架构 |
| --- | --- | --- |
| 新功能开发 | 需要时间 | 容易开发和实现 |
| 部署 | 不经常且容易部署 | 经常发布，部署复杂 |
| 隔离性 | 故障影响范围大 | 故障影响范围小 |
| 架构设计 | 难度小 | 难度级数增加 |
| 系统性能 | 响应时间快，吞吐量小 | 响应时间慢，吞吐量大 | 
| 系统运维 | 运维简单 | 运维复杂 |
| 新人上手 | 学习曲线大（应用逻辑）| 学习曲线大（架构逻辑）|
| 技术 | 技术单一且封闭 | 技术多样且开放 |
| 测试和查错 | 简单 | 复杂 |
| 系统扩展性 | 扩展性很差 | 扩展性很好 |
| 系统管理 | 重点在于开发成本 | 重点在于服务治理和调度 |

## 分布式系统的难点

亚马逊多年的实践让其可以运维和管理极其复杂的分布式服务架构原因：
1. 分布式服务的架构需要分布式的团队架构。按职责分工，而不是按技能分工。
2. 分布式服务差错不容易。一旦出现比较严重的故障，需要整体差错。
3. 没有专职的测试人员，也没有专职的运维人员，开发人员做所有的事情。
4. 运维优先，崇尚简化和自动化。
5. 内部服务和外部服务一致。

分布式系统中的不标准问题
1. 异构系统的不标准问题
主要表现在：
- 软件和应用不标准。
- 通讯协议不标准。
- 数据格式不标准。
- 开发和运维的过程和方法不标准。
2. 系统架构中的服务依赖性问题
- 如果非关键业务被关键业务所依赖，会导致非关键业务变成一个关键业务。
- 服务依赖链中，出现“木桶短板效应”————整个SLA由最差的那个服务所决定。
3. 故障发生的概率更大
- 出现故障不可怕，故障恢复时间过长才可怕。
- 出现故障不可怕，故障影响面过大才可怕。
4. 多层架构的运维复杂度更大
通常来说，可以把系统分成四层：基础层、平台层、应用层和接入层。
- 基础层就是我们的机器、网络和存储设备等。
- 平台层就是我们的中间件层，Tomcat、MySQL、Redis、Kafka之类的软件。
- 应用层就是我们的业务软件。
- 接入层就是接入用户请求的网关、负载均衡或是CDN、DNS这样的东西。
对于这四层，我们需要知道：
- 任何一层的问题都会导致整体的问题；
- 没有统一的视图和管理，导致运维被割裂开来，造成更大的复杂度。

分工不是问题，问题是分工后的协作是否统一和规范。

## 分布式系统的技术栈

构建分布式系统的目的是增加系统容量，提高系统的可用性，转换成技术方面，也就是完成下面两件事：
1. 提高整体架构的吞吐量，服务更多的并发和流量。
2. 提高系统的稳定性，让系统的可用性更高。

提高架构的性能
- 缓存系统。加入缓存系统，可以有效地提高系统的访问能力。从前端的浏览器，到网络，再到后端的服务，底层的数据库、文件系统、硬盘和CPU，全都有缓存，这是提高快速访问能力最有效的手段。
- 负载均衡系统。负载均衡系统是水平扩展的关键技术，它可以使用多台机器来共同分担一部分流量请求。
- 异步调用。异步系统主要通过消息队列来对请求做排队处理，这样可以把前端的请求的峰值给“削平”了，而后端通过自己能够处理的速度来处理请求。
- 数据分区和数据镜像。数据分区是按一定的方式分成多个去，不同的数据区来分担不同区的流量。这需要一个数据路由的中间件，会导致跨库的Join和跨库的事务非常复杂。而数据镜像是把一个数据库镜像成多份一样的数据，这样就不需要数据路由的中间件了。可以在任意结点上进行读写，内部会自行同步数据。然而，数据镜像中最大的问题就是数据的一致性问题。

https://static001.geekbang.org/resource/image/a9/17/a9edeae125a80f381003d8d9d0056317.png?wh=863*321

提高架构的稳定性
- 服务拆分。服务拆分主要有两个目的：一是为了隔离故障，二是为了重用服务模块。但服务拆分完之后，会引入服务调用间的依赖问题。
- 服务冗余。服务冗余是为了去除单点故障，并可支持服务的弹性伸缩，以及故障迁移。然而，对于一些有状态的服务来说，冗余这些有状态的服务带来了更高的复杂性。其中一个是弹性伸缩时，需要考虑数据的复制或是重新分片，迁移的时候还要迁移数据到其它机器上。
- 限流降级。当系统实在扛不住压力时，只能通过限流或者功能降级的方式来停掉一部分服务，或是拒绝一部分用户，以确保整个架构不会挂掉。这些技术属于保护措施。
- 高可用架构。通常来说高可用架构是从冗余架构的角度来保障可用性。
- 高可用运维。高可用运维指的是DevOps中的CI/CD（持续集成/持续部署）。

https://static001.geekbang.org/resource/image/be/79/befd21e1b41a257c5028f8c1bc7fa279.png?wh=865*315

分布式系统的关键技术
- 服务治理、服务拆分、服务调用、服务发现、服务依赖、服务的关键度定义......服务治理的最大意义是需要把服务间的依赖关系、服务调用链，以及关键的服务给梳理出来，并对这些服务进行性能和可用性方面的管理。
- 架构软件管理。服务之间有依赖，而且有兼容性问题，所以，整体服务所形成的架构需要有架构版本管理、整体架构的生命周期管理，以及对服务的编排、聚合、事务处理等服务调度功能。
- DevOps。分布式系统可以更为快速地更新服务，但是对于服务的测试和部署都会是挑战。所以，还需要DevOps的全流程，其中包括环境构建、持续集成、持续部署等。
- 自动化运维。有了DevOps后，我们就可以对服务进行自动伸缩、故障迁移、配置管理、状态管理等一系列的自动化运维技术了。
- 资源调度管理。应用层的自动化运维需要基础层的调度支持，也就是云计算laas层的计算、存储、网络等资源调度、隔离和管理。
- 整体架构监控。这里的监控需要对三层系统（应用层、中间件层、基础层）进行监控。
- 流量控制。负载均衡、服务路由、熔断、降级、限流等和流量相关的调度都会在这里，包括灰度发布之类的功能也在这里。

分布式的五个关键技术：
1. 全栈系统监控
2. 服务/资源调度
3. 流量调度
4. 状态/数据调度
5. 开发和运维的自动化

https://static001.geekbang.org/resource/image/8e/db/8e92e2dff4f66147c014f930aa678fdb.jpg?wh=2556x1006

## 分布式系统关键技术

### 全栈监控

- 基础层：监控主机和底层资源。比如：CPU、内存、网络吞吐、硬盘I/O、硬盘使用等。
- 中间层：中间件层的监控。比如：Nginx、Redis、ActiveMQ、Kafka、MySQL、Tomcat等。
- 应用层：监控应用层的使用。比如：HTTP访问的吞吐量、响应时间、返回码、调用链路分析、性能瓶颈，还包括用户端的监控。

https://static001.geekbang.org/resource/image/fe/4f/fe3aaf79df1565505cdac32494078a4f.jpg?wh=2145x1152

监控的标准化：
- 日志数据结构化；
- 监控数据格式标准化；
- 统一的的监控平台；
- 统一的日志分析。

不好的监控系统问题：
1. 监控数据是隔离开来的。
2. 监控的数据项太多。

好的监控系统应该有以下几个特征：
- 关注于整体应用的SLA。主要从为用户服务的API来监控整个系统。
- 关联指标聚合。把有关联的系统及其指标聚合展示。主要是三层系统数据：基础层、平台中间件层和应用层。
- 快速故障定位。快速定位问题需要对整个分布式系统做一个用户请求跟踪的trace监控，需要监控到所有的请求在分布式系统中的调用
链，最好是做成没有侵入性的。

好的监控系统为以下两个场景设计：
1. 体检。
- 容量管理。提供一个全局的系统运行时数据的展示，可以让工程师团队知道是否需要增加及其或者其它资源。
- 性能管理。可以通过查看大盘，找到系统瓶颈，并有针对性地优化系统和相应代码。
2. 急诊。
- 定位问题。可以快速地暴露并找到问题的发生点，帮助技术人员诊断问题。
- 性能分析。当出现非预期的流量提升时，可以快速地找到系统的瓶颈，并帮助开发人员深入代码。

如何做出好的监控系统。
- 服务调用链跟踪。这个监控系统应该从对外的API开始，然后将后台的实际服务给关联起来，然后再进一步将这个服务的依赖服务关联起来，直到最后一个服务，这样就可以把整个系统的服务全部串连起来。最佳实践是Google Dapper系统。
- 服务调用时长分布。使用Zipkin，可以看到一个服务调用链上的时间分布，这样有助于知道最耗时的服务是什么。
- 服务的TOP N视图。所谓TOP N视图就是一个系统请求的排名情况。一般来说，这个排名会有三种排名的方法：a) 按调用量排名，b)按请求最耗时排名，c) 按热点排名（一个时间段内的请求次数和响应时间和）。
- 数据库看看操作关联。
- 服务资源跟踪。把服务运行的机器节点上的数据（如CPU、MEM、I/O、DISK、NETWORK）
关联起来。

https://static001.geekbang.org/resource/image/6b/33/6b17dd779cfecd62e02924dc8618e833.png?wh=865*381

### 服务调度

服务调度的关键技术：
- 服务关键程度
- 服务依赖关系
- 服务发现
- 整个架构的版本管理
- 服务应用生命周期全管理

服务关键程度和服务的依赖关系
- 微服务是服务依赖最优解的上限，而服务依赖的下限是千万不要有依赖环。如果系统架构中有服务依赖管，那么表明架构设计是错误的。循环依赖有很多的副作用，最大的问题是这是一种极强的耦合，会导致服务部署相当复杂和难解，而且会导致无穷尽的递归故障和一些意想不到的问题。
- 解决服务依赖环的方案一般是，依赖倒置的设计模式。在分布式架构上，可以使用一个第三方的服务来解决这个事。
- 服务的依赖关系是可以通过技术的手段来发现的，其中Zipkin是一个很不错的服务调用跟踪系统，是通过Google Dapper这篇论文来实现的。

服务状态和生命周期的管理
需要有一个服务注册中心，知道服务运作的状态和情况

服务的生命周期通常会有以下几个状态：
- Provision，代表在供应一个新的服务；
- Ready，表示启动成功了；
- Run，表示通过了服务健康检查；
- Update，表示在升级中；
- Rollback，表示在回滚中；
- Scale，表示正在伸缩中（可以有Scale-in和Scale-out两种）；
- Destroy，表示在销毁中；
- Failed，表示失败状态。

整个架构的版本管理
亚马逊VersionSet，由一堆服务的版本集所形成的整个架构的版本控制。
需要一个架构的manifest，一个服务清单，这个服务清单定义了所有富的版本运行环境，其中包括但不限于：
- 服务的软件版本；
- 服务的运行环境——环境变量、CPU、内存、可以运行的节点、文件系统等；
- 服务运行的最大最小实例数。
每次对这个清单的变更都需要被记录下来，算是一个架构的版本管理。而集群控制系统需要能够解读并执行这个清单中的变更，以操作和管理整个集群中的相关变更。

资源/服务调度
服务和资源的调度有点像操作系统。操作系统一方面把用户进程在硬件资源上进行调度，另一方面提供进程间的通信方式，可以让不同的进程在一起协同工作。服务和资源调度的过程，与操作系统调度进程的方式相似，有如下关键技术：
- 服务状态的维持和拟合。
- 服务的弹性伸缩和故障迁移。
- 作业和应用调度。
- 作业工作流编排。
- 服务编排。

服务状态的维持和拟合
服务运行过程中状态的变化有两种：
1. 一种是没有预期的变化。好的集群控制器应该能够强行维护服务的状态。在健康的实例数变少时，控制器会把不健康的服务给摘除，而又启动新的，强行维护健康的服务实例数。 
2. 预期的变化。从一个状态拟合到另一个状态，而且要穷尽所有的可能，不断地拟合直到达到目的。

对于分布式系统的服务管理，需要把一个状态变成另一个状态时，需要对集群进行一系列的操作，如对集群进行Scale时，
- 先扩展出几个结点；
- 再往上部署服务；
- 然后启动服务；
- 再检查服务的健康情况；
- 最后把新扩展出来的服务实例加入服务发现中提供服务。

服务的弹性伸缩和故障迁移
所需要的操作步骤：
- 底层资源的伸缩；
- 服务的自动化部署；
- 服务的健康检查；
- 服务发现的注册；
- 服务流量的调度。

故障迁移的两个模式：
1. 宠物模式，一定要救活，主要是对于stateful的服务。
2. 奶牛模式，不用救活，重新生成一个实例。

运行涉及的问题：
1. 服务的健康监控（需要一个APM的监控）。
2. 宠物模式，需要：服务的重新启动和服务的监控报警。
3. 奶牛模式，需要：服务的资源申请，服务的自动化部署，服务发现的注册，以及服务的流量调度。

服务工作流和编排
需要一个API Gateway或一个简单的消息队列来做相应的编排工作。

### 流量与数据调度

流量调度的主要功能
1. 根据系统运行的情况，自动地进行流量调度，在无需人工干预的情况下，提升整个系统的稳定性；
2. 让系统应对爆品等突发事件时，在弹性计算扩缩容的较长时间窗口内或底层资源消耗殆尽的情况下，保护系统平稳运行。

流量调度系统还可以完成以下几个方面的事情：
- 服务流控。服务发现、服务路由、服务降级、服务熔断、服务保护等。
- 流量控制。负载均衡、流量分配、流量控制、异地灾备（多活）等。
- 流量管理。协议转换、请求校验、数据缓存、数据计算等。
这些都是一个API Gateway应该做的事情。

流量调度的关键技术
1. API Gateway必须使用高性能的技术，所以需要使用高性能的语言。
2. 扛流量。要能扛流量，就需要使用集群技术。集群技术的关键点是在集群内的各个结点中共享数据。这就需要使用像Paxos、Raft、Gossip这样的通讯协议。
3. 业务逻辑。 API Gateway需要有简单的业务逻辑，可以让人注入不同语言的简单业务逻辑。
4. 服务化。一个好的API Gateway需要能够通过Admin API来不停机地管理配置变更，而不是手动更改.conf。

要解决数据不丢失的问题，只能通过数据冗余的方法，就算是数据分区，每个区也需要进行数据冗余处理。这就是数据副本。当出现某个节点的数据丢失时，可以从副本读到。数据副本是分布式系统解决数据丢失异常的唯一手段。简单来说：
1. 要想数据有高可用性，就得写多份数据。
2. 写多份会引起数据一致性的问题。
3. 数据一致性的问题又会引发性能问题。

解决数据副本间的一致性问题时，会有一些技术方案。
- Master-Slave方案
- Master-Master方案
- 两阶段和三阶段提交方案
- Paxos方案。
https://static001.geekbang.org/resource/image/82/33/826e501a90a297815469564d23454233.jpg?wh=1563x1134

## PaaS平台的本质

### 一家商业公司的软件工程能力
1. 提高服务的SLA。就是能提供多少个9的系统可用性，而每提高一个9的可用性都是对整个系统架构的重新洗礼。提高系统的SLA主要体现在两个方面：
- 高可用的系统；
- 自动化的运维。
故障是常态，需要一个高度自动化的运维和管理系统，提高服务的SLA。

2. 能力和资源重用或服用
体现在两个方面：
- 软件模块的重用；
- 软件运行环境和资源的重用
为此需要“软件抽象的能力”和“软件标准化的能力”。

3. 过程的自动化
把软件生产和运维的过程自动化起来，也就是软件生产流水线和软件运维自动化。

### 分布式的技术点
- 分布式多层的系统架构
- 服务化的能力供应
- 自动化的运维能力

### PaaS 平台的本质
一个好的PaaS平台应该具有分布式、服务化、自动化部署、高可用、敏捷及分层开放的特征，并可与laaSshi实现良好的联动。

下面是PaaS跟软件中间件最大的差别
- 服务化是PaaS的本质。 软件模块重用，服务治理，对外提供能力是PaaS的本质。
- 分布式是PaaS的根本特性。多租户隔离、高可用、服务编排是PaaS的基本特性。
- 自动化是PaaS的灵魂。自动化部署安装运维，自动化伸缩调度是PaaS的关键。

PaaS平台的总体架构
https://static001.geekbang.org/resource/image/f6/68/f65ccf66daf8d01d59fa8948c8136c68.png?wh=865*582

一个完整的PaaS平台会包括以下几部分。
- PaaS调度层-主要是PaaS的自动化和分布式对于高可用高性能的管理。
- PaaS能力服务层-主要是PaaS真正提供给用户的服务和能力。
- PaaS的流量调度-主要是与流量调度相关的东西，包括对高并发的管理。
- PaaS的运维管理-软件资源库、软件接入、认证和开放平台门户。
- PaaS的运维管理-主要是DevOps相关的东西。

PaaS平台的生产和运维：
https://static001.geekbang.org/resource/image/97/38/9740e0fe4225f5a3d7843e46582d3938.png?wh=3132x1416

# 编程范式

## 起源

什么是编程范式：
Programming Paradigm，范式即模式、方法，是一类典型的编程风格，是指从事软件工程的一类典型的风格。

C语言拥有的特性：
1. C语言是一个静态弱类型语言，在使用变量时需要声明变量类型，但是类型间可以有隐式转换；
2. 不同的变量类型可以用结构体（struct）组合在一起，以此来声明新的数据类型；
3. C语言可以用typedef 关键字来定义类型的别名，以此来达到变量类型的抽象；
4. C语言是一个有结构化程序色剂、具有变量作用域以及递归功能的过程式语言；
5. C语言传递参数一般是以值传递，也可以传递指针；
6. 通过指针，C语言可以容易地对内存进行低级控制，然而这加大了编程复杂度；
7. 编程预处理让C语言的编译更有弹性，比如跨平台。

推荐：斯坦福编程范式公开课、冒号课堂、七周七语言

## 泛型编程

推荐：C++语言的设计和演化

### C++语言

C++解决了C语言的如下问题：
1. 用引用来解决指针的问题。
2. 用namespace 来解决名字空间冲突的问题。
3. 通过try-catch 来解决检查返回值编程的问题。
4. 用class 来解决对象的创建、复制、销毁的问题，从而可以达到在结构体嵌套时可以深度复制的内存安全问题。
5. 通过重载操作符来达到操作上的泛型。
6. 通过模板template 和虚函数的多态以及运行时识别来达到更高层次的泛型和多态。
7. 用RAII、智能指针的方式，解决了C语言中因为需要释放资源而出现的那些非常ugly也很容易出错的代码的问题。
8. 用STL解决了C语言中算法和数据结构的N多坑。

C++解决程序泛型问题有三种方法：
1. 通过类的方式来解决。
- 类里面会有构造函数、析构函数表示这个类的分配和释放。
- 拷贝构造函数，表达了对内存的复制。
- 重载操作符，要去比较大于、等于、不等于。
2. 通过模板达到类型和算法的妥协。
- 模板像DSL，模板的特化会根据使用者的类型在编译时期生成那个模板的代码。
- 模板可以通过一个虚拟类型来做类型绑定，这样不会导致类型转换时的问题。
模板很好地取代C时代宏定义带来的问题。
3. 通过虚函数和运行时类型识别。
- 虚函数带来的多态在语义上可以支持“同一类”的类型泛型。
- 运行时类型识别技术可以做到在泛型时对具体类型的特殊处理。

一个良好的泛型编程需要解决如下几个泛型编程的问题：
1. 算法的泛型。
2. 类型的泛型。
3. 数据结构（数据容器）的泛型。

C语言的Search()
```C
int search(void* a, size_t size, void* target, 
  size_t elem_size, int(*cmpFn)(void*, void*) )
{
  for(int i=0; i<size; i++) {
    if ( cmpFn (a + elem_size * i, target) == 0 ) {
      return i;
    }
  }
  return -1;
}
```

C++语言的Search()
```C++
template<typename T, typename Iter>
Iter search(Iter pStart, Iter pEnd, T target) 
{
  for(Iter p = pStart; p != pEnd; p++) {
    if ( *p == target ) 
      return p;
  }
  return NULL;
}
```

推荐书籍：《STL源码解析》，《inside C++ model》

## 类型系统和泛型的本质

程序语言的类型系统主要提供如下的功能：
1. 程序语言的安全性。使用类型可以让编译器侦测一些代码的错误。强类型语言提供更多的安全性，但是并不能保证绝对的安全。
2. 利于编译器的优化。静态类型语言的类型声明，可以让编译器明确地知道程序员的意图。因此，编译器就可以利用这一信息做很多代码优化工作。
3. 代码的可读性。有类型的编程语言，可以让代码更易读和更易维护，代码的语义也更清楚，代码模块的接口（如函数）也更丰富和清楚。
4. 抽象化。类型允许程序设计者对程序以较高层次的方式思考，而不是低层次的实现。
但是，类型带来的问题就是我们作用于不同类型的代码，虽然长得非常相似，但是由于类型的问题需要根据不同版本写出不同的算法，如果要做到泛型，就需要涉及比较底层的玩法。

无论哪种程序语言，都避免不了一个特定的类型系统。
- 静态类型检查是在编译器进行语义分析时进行的。如果一个语言强制实行类型规则（即通常只允许以不丢失信息为前提的自动类型转换），那么称此处理为强类型，反之称为弱类型。
- 动态类型检查系统更多的是在运行时期做动态类型标记和相关检查。所以，动态类型的语言必然要给出一堆诸如：is_array(), is_int(), is_string() 或是typeof()这样的运行时类型检查函数。

类型的本质
- 类型是对内存的一种抽象。不同的类型，会有不同的内存布局和内存分配的策略。
- 不同的类型，有不同的操作。所以，对于特定的类型，也有特定的一组操作。

要做到泛型，需要做下面的事情：
- 标准化掉类型的内存分配、释放和访问。
- 标准化掉类型的操作。比如：比较操作，I/O操作，复制操作
- 标准化掉数据容器的操作。比如：查找算法、过滤算法、聚合算法
- 标准化掉类型上特有的操作。需要有标准化的接口来回调不同类型的具体操作

C++动用了非常繁多和复杂的技术来达到泛型编程的目标：
- 通过类中的构造、析构、拷贝构造，重载赋值操作符，标准化（隐藏）了类型的内存分配、释放和复制的操作。
- 通过重载操作符，可以标准化类型的比较等操作。
- 通过iostream，标准化了类型的输入、输出控制。
- 通过模板技术（包括模板的特化），来为不同的类型生成类型专属的代码。
- 通过迭代器来标准化数据容器的遍历操作。
- 通过面向对象的接口依赖（虚函数技术），来标准化了特定类型在特定算法上的操作。
- 通过函数式（函数对象），来标准化对于不同类型的特定操作。

泛型编程的本质：
屏蔽掉数据和操作数据的细节，让算法更为通用，让编程者更多地关注算法的结构，而不是在算法中处理不同的数据类型。

## 函数式编程

对于函数式编程来说，它只关心输入数据和输出数据相关的关系，数学表达式里面其实是在做一种映射（mapping），输入的数据和输出的数据关系是什么样，是用函数来定义的。

函数式编程的特点：
- staless:函数式不维护任何状态。函数式编程的核心精神是stateless，简而言之就是它不能存在状态，里面的数据是不变的。
- immutable:输入数据是不能动的，动了输入数据就有危险，所以要返回新的数据集。

函数式编程的优势：
- 没有状态就没有伤害。
- 并行执行无伤害。
- Copy-Paste重构代码无伤害。
- 函数的执行没有顺序上的问题。
- 惰性求职。需要编译器的支持，表达式不在它被绑定到变量之后就立即求值，而是在该值被取用的时候求值。
- 确定性。在一个参数，在不同的场景下会计算出不同的结构，这个称之为函数的确定性。

函数式编程的劣势：
- 数据复制比较严重。
- 完全函数式Haskell。
- 容易写纯函数F#，Ocaml，Clojure，Scala
- 纯函数需要花点精力C#，Java，JavaScript

函数式编程用到的技术
- first class function(头等函数)：这个技术可以让函数像变量一样来使用。函数可以像变量一样被创建、修改，并当成变量一样传递、返回，或是在函数中嵌套函数。
- tail recursion optimization(尾递归优化)：如果递归很深，stack受不了会导致性能大幅度下降。如果语言或编译器支持，可使用尾递归优化技术，每次递归时重用stack。Python不支持。
- map&reduce：函数式编程最常见的技术就是对一个集合做Map和Reduce操作。
- pipeline(管道)。将函数实例成一个个action，然后将一组action放到一个数组或是列表，再将数据传给action list，数据就像一个pipeline一样顺序地被各个函数操作。
- recursing(递归)：递归最大的好处就是简化代码，可以把一个复杂的问题用很简单的代码描述出来。
- currying(柯里化)：将一个函数的多个参数分解成多个函数，然后将函数多层封装起来，每层函数都返回一个函数去接收下一个参数，这可以简化函数的多个参数。
- high order function(高阶函数)：函数当作参数，把传入的函数做一个封装，，然后返回这个封装函数。适合做Decorator。

函数式编程的理念：
1. 把函数当成变量来用，关注描述问题而不是怎么实现，可以让代码更易读。
2. 因为函数返回里面的这个函数，所以函数关注的是表达式，关注的是描述这个问题，而不是怎么实现这个事情。

过程式编程范式叫做Imperative Programming指令式编程
函数式编程范式叫做Declarative Programming声明式编程

函数式语言的三套件：
Map、Reduce、Filter，map和reduce不关心源输入数据，它们只是控制，并不是业务。控制是描述怎么干，而业务是描述要干什么。

## 修饰器模式

修饰器的作用：
1. 表面上看，修饰器模式就是扩展现有的一个函数的功能，让它可以干一些其他的事，或是在现有的函数功能上再附加上一些别的功能。
2. 函数式编程下的代码扩展能力，还能感受到函数的互相和随意拼装带来的好处。
3. Decorator这个函数是可以修饰几乎所有的函数的。于是，这种可以通过于其他函数的编程方式，可以很容易地将一些非业务功能的、属于控制类型的代码给抽象出来（指像for-loop，或是打日志，或是函数路由，或是求函数运行时间之类的非业务功能性的代码）

## 面向对象编程

面向对象编程（Object-oriented programming, OOP），有三大特性：封装、继承和多态。

面向对象编程是一种具有对象概念的程序编程范型，同时也是一种程序开发的抽象方针，它可能包含数据、属性、代码与方法。对象则指的是类的实例。它将对象作为程序的基本单元，将程序和数据封装其中，以提高软件的可重用性、灵活性和可扩展性，对象里的程序可以访问及修改对象相关联的数据。在面向对象编程里，计算机程序会被设计成彼此相关的对象。

两个面向对象的核心理念：
1. Program to an interface, not an implementation.
- 使用者不需要知道数据类型、结构、算法的细节。
- 使用者不需要知道实现细节，只需要知道提供的接口。
- 利于抽象、封装、动态绑定、多态。
- 符合面向对象的特质和理念。
2. Favor object composition over class inheritance.
- 继承需要给子类暴露一些父类的设计和实现细节。
- 父类实现的改变会造成子类也需要改变。
- 继承不只是为了代码重用，实际上在子类中需要重新实现很多父类的方法。
- 继承更多的应该是为了多态。

面向对象的优缺点
1. 优点
- 能和真实的世界交相辉映，符合人的直觉。
- 面向对象和数据库模型设计类型，更多地关注对象间的模型设计。
- 强调于“名词”而不是“动词”，更多地关注对象和对象间的接口。
- 根据业务的特征形成一个个高内聚的对象，有效地分离了抽象和具体实现，增强了可重用性和可扩展性。
- 拥有大量非常优秀的设计原则和设计模式。
- S.O.L.I.D（单一原则、开闭原则、里氏替换、接口隔离以及依赖反转，是面向对象设计的五个基本原则）、IoC/DIP......
2. 缺点
- 代码都需要附着在一个类上，从一侧面上说，其鼓励了类型。
- 代码需要通过对象来达到抽象的效果，导致了相当厚重的“代码粘合层”。
- 因为太多的封装以及对状态的鼓励，导致了大量不透明并在并发下出现很多问题。

推荐书籍：Erich Gamma、Richard Helm、Ralph Johnson 和 John Vlissides 合作出版的《设计模式：可复用面向对象软件的基础》（Design Patterns - Elements of Reusable Object-Oriented Software）

## 基于原型的编程范式

基于原型的编程范式就是一种委托的方式。在使用委托的基于原型的语言中，运行时语言可以“仅仅通过序列的指针找到匹配”这样的方式来定位属性或者寻找正确的数据。所有这些创建行为、共享的行为需要的是委托指针。

## Go语言的委托模式

## 编程的本质
https://static001.geekbang.org/resource/image/4a/92/4a8c7c77df1f1a6b3ff701577986ee92.png?wh=1768*555

代码复杂度的原因：
1. 业务逻辑的复杂度决定了代码的复杂度；
2. 控制逻辑的复杂度 + 业务逻辑的复杂度 ==> 程序代码的混乱不堪；
3. 绝大多数程序复杂混乱的根本原因：业务逻辑与控制逻辑的耦合。

如何分离control和logic？
1. State Machine
- 状态定义
- 状态变迁条件
- 状态的action
2. DSL-Domain Specific Language
HTML，SQL，Unix Shell Script，AWK，正则表达式
3. 编程范式
- 面向对象：委托、策略、桥接、修饰、IoC/DIP、MVC
- 函数式编程：修饰、管道、拼装
- 逻辑推导式编程：Prolog

编程的本质：
Logic部分才是真正有意义的（What）
Control部分只是影响Logic部分的效率（How）
 
## 逻辑编程范式

逻辑编程范式的几个特征：
1. 逻辑编程的要点是将正规的编辑风格带入到计算机程序设计之中。
2. 逻辑编程建立了描述一个问题里的世界的逻辑模型。
3. 逻辑编程的目标是对它的模型建立新的陈述。
4. 通过陈述事实——因果关系。
5. 程序自动推导出相关的逻辑。

## 编程范式总结
编程范式，可以分为几类：
声明式、命令式、逻辑的、函数式、面向对象的、面向过程的

声明式编程范式（函数式和逻辑式）偏向于你定义要什么，而不是怎么做。
而两边的命令式编程范式和面向对象编程范式，偏向于怎么做，而不是做什么。

https://static001.geekbang.org/resource/image/9d/8d/9d6ac4820cc070a6b567d3f514d9ea8d.png?wh=1502*1125

https://static001.geekbang.org/resource/image/4b/3c/4b764c2eab8f6f383525e6d1a386d93c.jpg?wh=1860x1353

https://static001.geekbang.org/resource/image/bf/ef/bf6945c2ca2ec5564ecbbf1c81503eef.png?wh=1650*862

https://static001.geekbang.org/resource/image/37/25/37215aac89a3fc78d1d99649a0f91a25.jpg?wh=1950x2010

# 弹力设计

## 认识故障和弹力设计

系统可用性测量：
Availability = MTTF / MTTF + MTTR，
Mean Time To Failure，平均故障前的时间，即系统平均能够正常运行多长时间才发生一次故障。系统的可靠性越高，MTTF越长。
MTTR是Mean Time To Recovery，平均修复时间，即从故障出现到故障修复的这段时间，这段时间越短越好。

https://static001.geekbang.org/resource/image/6c/11/6ca2f7ba3537b341c9f6701fc7e25711.png?wh=1728x1180

故障原因
1. 无计划的
- 系统级故障，包括主机、操作系统、中间件、数据库、网络、电源以及外围设备。
- 数据和中介的故障，包括人员误操作、硬盘故障、数据乱了。
- 自然灾害、人为破坏，以及供电问题。
2. 有计划的
- 日常任务：备份，容量规划，用户和安全管理，后台批处理应用。
- 运维相关：数据库维护、应用维护、中间件维护、操作系统维护、网络维护。
- 升级相关：数据库、应用、中间件、操作系统、网络，包括硬件升级。

归类：
1. 网络问题。
2. 性能问题。
3. 安全问题。
4. 运维问题。
5. 管理问题。
6. 硬件问题。

### 故障不可避免
https://static001.geekbang.org/resource/image/bd/3e/bd48fbd74405e8380defdf708b6b3e3e.png?wh=865*381

1. 故障是正常的，而且是常见的。
2. 故障是不可预测突发的，而且相当难缠。

## 隔离设计

### 按服务的种类来做分离

https://static001.geekbang.org/resource/image/34/eb/34e3b94399f89a825a0046234607f9eb.png?wh=865*415

### 按用户的请求来做分离

https://static001.geekbang.org/resource/image/a7/5e/a7293c5fe813a7e8e2498aac34c4825e.png?wh=865*482

多租户的做法通常有三种：
1. 完全独立的设计。每个租户有自己完全独立的服务和数据。
2. 独立的数据分区，共享的服务。多租户的服务是共享的，但数据是分开隔离的。
3. 共享的服务，共享的数据分区。每个租户的数据和服务都是共享的。

https://static001.geekbang.org/resource/image/0c/9c/0c7cb0d25fb2c65a8db011ba61b8729c.png?wh=865*612

### 隔离设计的重点

做好隔离设计，需要有如下的设计考量：
1. 需要定义好隔离业务的大小和颗粒度。需要认真地做业务上的需求和系统分析。
2. 无论是做系统板块还是多租户的隔离，都需要考虑系统的复杂度、成本、性能、资源使用的问题，找到一个合适的均衡方案，或是分布实施的方案尤其重要，需要做好取舍。
3. 隔离模式需要配置一些高可用、重试、异步、消息中间件，流控、熔断等设计模式的方式配套使用。
4. 分布式系统中的运维的复杂度的提升，要驾驭好还需要很多自动化运维的工具，尤其是使用像容器或是虚拟机这样的虚拟化技术便于管理。
5. 需要一个非常完整的能够看得到所有服务的监控系统，十分重要。

## 异步通讯设计

同步调用的四个问题：
1. 影响吞吐量。同步调用需要被调用方的吞吐不低于调用方的吞吐，否则会导致被调用方因为性能不足而拖死调用方，即整个同步调用链的性能会由最慢的那个服务决定。
2. 消耗系统资源。调用方需要保存现场（context）等待远端返回，所以对于并发比较高的场景来说，这样的等待可能会极度消耗资源。
3. 只能一对一。
4. 多米诺骨牌效应。

所以，异步通讯对于同步通讯来说，除了可以增加系统的吞吐量外，最大的好处是可以让服务间的解耦更为彻底，系统的调用方和被调用方可以按照自己的速率而不是步调一致，从而可以更好地保护系统，让系统更有弹力。

异步调用的三种方式：
1. 请求响应
2. 直接订阅
3. 中间人订阅

### 请求响应式
这种情况下，发送方（sender）会直接请求接收方（receiver），被请求方接收到请求后，直接返回——收到请求，正在处理。

对于返回结果，有两种方法：
1. 发送方时不时地去轮询一下。
2. 发送方注册一个回调方法，也就是接收方处理完后回调请求方。

这种情况还是有耦合的。是发送方依赖于接收方，并且要把自己的回调发送给接收方，处理完后回调。

### 通过订阅的方式
这种情况下，接收方（receiver）会来订阅发送方（sender）的消息，发送方会把相关的消息或数据放到接收方所订阅的队列中，而接收方会从队列中获取数据。这种方式下，发送方并不关心订阅方的处理结果，只是告诉订阅方有事要干，收完消息后给个ACK就好。

https://static001.geekbang.org/resource/image/d8/37/d8d96ed4e4616626b9e079dc13637937.png?wh=865*751

这种方式下，接收方需要发送方订阅事件，所以还是接收方依赖于发送方。这种方式还是有一定的耦合。

### 通过Broker的方式
Broker，就是一个中间人，发送方（sender）和接收方（receiver）都互相看不到对方，它们看得到的是一个Broker，发送方向Broker发送消息，接收方向Broker订阅消息。

https://static001.geekbang.org/resource/image/82/23/82ddd9f2015527b9754e77f332790323.jpg?wh=2052x660

这是完全的解耦。所有的服务都不需要相互依赖，而是依赖于一个中间件Broker。这个Broker是一个像数据总线一样的东西，所有的服务要接收数据和发送数据都发到这个总线上，这个总线就像协议一样，让服务间的通讯变得标准和可控。

在Broker这种模式下，发送方的服务和接收方的服务最大程度地解耦。但是所有人都依赖于一个总线，这个总线需要有如下的特性：
- 必须是高可用的，因为它成了整个系统的关键；
- 必须是高性能而且是可以水平扩展的；
- 必须是可以持久化不丢数据的。

### 事件驱动设计

事件驱动架构（EDA - Event Driver Architecture）。事件驱动最好是使用Broker方式，服务间通过交换消息来完成交流和整个流程的驱动。

这是一个订单处理流程。下单服务通知订单有订单要处理，而订单服务生成订单后发出通知，库存服务和支付服务得到通知后，一边是占住库存，另一边是让用户支付，等待用户支付完成后通知配送服务进行商品配送。
https://static001.geekbang.org/resource/image/b7/0b/b7d1f3c287de6ef999d1b719ea974c0b.jpg?wh=3522x690

每个服务都是“自包含”的，没有和别人产生依赖。

事件驱动方式的好处：
1. 服务间的依赖没有了，服务间是平等的，每个服务都是高度可重用并可被替换的。
2. 服务的开发、测试、运维，以及故障处理都是高度隔离的。
3. 服务间通过事件关联，所以服务间是不会相互block的。
4. 在服务间增加一些Adapter（如日志、认证、版本、限流、降级、熔断等）相当容易。
5. 服务间的吞吐也被解开了，各个服务可以按照自己的处理速度处理。

事件驱动的架构也会有不好的地方：
1. 业务流程不再那么明显和好管理。整个架构变得比较复杂。解决这个问题需要有一些可视化的工具来呈现整体业务流程。
2. 事件可能会乱序。这会带来非常Bug的事。解决这个问题需要很好地管理一个状态机的控制。
3. 事务处理变得复杂。需要使用两阶段提交来做强一致性，或是退缩到最终一致性。

### 异步通讯的设计重点

为什么要异步通讯：
1. 异步通讯最重要的是解耦服务间的依赖。最佳解耦的方式是通过Broker的机制。
2. 解耦的目的是让各个服务的隔离性更好，这样不会出现“一倒倒一片”的故障。
3. 异步通讯的架构可以获得更大的吞吐量，而且各个服务间的性能不受干扰相对独立。
4. 利用Broker或队列的方式啊还可以达到把抖动的吞吐量编程均匀的吞吐量，达到“削峰”。
5. 服务相对独立，在部署、扩容和运维上都可以做到独立不受其他服务的干扰。

异步通讯的注意事宜：
1. 用于异步通讯的中间件Broker成为了关键，需要设计成高可用不丢消息的。另外，因为是分布式的，所以可能很难保证消息的顺序，因此设计最好不依赖于消息的顺序。
2. 异步通讯会导致业务处理流程不那么直观，因为像接力一样，所以在Broker上需要有相关的服务消息跟踪机制，否则出现问题后不容易调试。
3. 因为服务间只通过消息交互，所以业务状态最好由一个总控方来管理，这个总控方维护一个业务流程的额状态变迁逻辑，以便系统发生故障后知道业务处理到了哪一步，从而可以在故障清除后继续处理。

消息队列中，可能有的业务逻辑会有像TCP协议那样的send和ACK机制。需要处理方有幂等的处理，即同一条消息无论收到多少次都只处理一次。

## 幂等性设计

把系统解耦隔离后，服务间的调用可能会有三个状态，一个是成功（Success），一个是失败（Failed），一个是超时（Timeout）。前两者都是明确的状态，而超时则是完全不知道是什么状态。

因为系统超时，而调用方重试一下，会给系统带来不一致的副作用。一般有两种处理方式：
1. 需要下游系统提供相应的查询接口。上游系统在timeout后去查询一下。如果查到了，就表明已经做了，成功了就不用做了，失败了就走失败流程。
2. 通过幂等性的方式。也就是说，把这个查询操作交给下游系统，上游系统只管重试，下游系统保证一次和多次的请求结果是一样的。

对于第一种方式，需要对方提供一个查询接口来做配合。而第二种方式则需要下游的系统提供支持幂等性的交易接口。

### 全局ID
要做到幂等性的交易接口，需要有一个唯一的标识，来标志交易是同一笔交易。这个标识要能做到全局唯一。

为了解决分配冲突的问题，需要使用一个不会冲突的算法，比如使用UUID这样冲突非常小的算法。但UUID的问题是，它的字符串占用的空间比较大，索引的效率非常低，生成的ID太过于随机，完全不是人读的，而且没有递增，如果要按前后顺序排序的话，基本不可能。

推荐：Twitter的开源项目Snowflake。是一个分布式ID的生成算法。它的核心思想是，产生一个long型的ID。
- 41bits 作为毫秒数。大概可以用 69.7 年。
- 10bits 作为机器编号（5bits 是数据中心，5bits 的机器 ID），支持 1024 个实例。
- 12bits 作为毫秒内的序列号。一毫秒可以生成 4096 个序号。

https://static001.geekbang.org/resource/image/2f/38/2f637bc4789b00cdb4bb05f510cefd38.jpg?wh=2286x1083

### 处理流程
对于幂等性的处理流程来说，说白了就是要过滤一下已经收到的交易。要做到这个事，需要一个存储来记录收到的交易。

幂等性也是分布式的，所以，需要这个存储也是共享的。这样每个服务就变成没有状态的。但是，这个存储就成了一个非常关键的依赖，其扩展性和可用性也成了非常关键的指标。

可以使用关系型数据库，或是 key-value 的 NoSQL（如 MongoDB）来构建这个存储系统。

### HTTP的幂等性

HTTP GET 方法用于获取资源，不应有副作用，所以是幂等的。强调的是一次和N次具有相同的副作用，而不是每次GET的结果相同。

HTTP HEAD和GET本质是一样的，区别在于HEAD不含有呈现数据，而仅仅是HTTP头信息，不应有副作用，也是幂等的。

HTTP OPTIONS主要用于获取当前URL所支持的方法，所以也是幂等的。

HTTP DELETE方法用于删除资源，有副作用，但它应该满足幂等性。

HTTP POST方法用于创建资源，所对应的URL并非创建的资源本身，而是去执行创建动作的操作者，有副作用，不满足幂等性。

HTTP PUT方法用于创建或更新操作，所对应的URL是要创建或更新的资源本身，有副作用，它应该满足幂等性。

一般幂等性的设计如下：
1. 首先，在表单中需要隐藏一个token，这个token可以是前端生成的一个唯一的ID。用于防止用户多次点击了表单提交按钮，而导致后端收到了多次请求，却不能分辨是否是重复的提交。这个token是表单的唯一标识。
2. 然后，当用户点击提交后，后端会把用户提交的数据和这个token保存在数据库中。如果有重复提交，那么数据库中的token会做排它限制，从而做到幂等性。
3. 更为稳妥的做法是，后端成功后向前端返回302跳转，把用户的前端页跳转到GET请求，把刚刚POST的数据给展示出来。如果是Web上的最好还把之前的表单设置成过期，这样用户不能通过浏览器后退按钮来重新提交。这个模式又叫做RPG模式（Post/Redirect/Get）。

## 服务的状态

“状态”，就是为了保留程序的一些数据或是上下文。

无状态的服务就像一个函数，对于给定的输入，它会给出唯一确定的输出。它的好处是很容易运维和伸缩，但需要底层有分布式的数据库支持。

有状态的服务，通过Sticky Session、一致性Hash和DHT等技术实现状态和请求的关联，并将数据同步到分布式数据库中；利用分布式文件系统，还能在节点挂掉时快速启动新实例。

### 无状态的服务Staless
无状态的服务和“函数式编程”的思维方式是一致的，函数是immutable不变的，所有的函数只描述其逻辑和算法，根本不保存数据，也不会修改输入的数据，而是把计算好的结果返回出去，哪怕要把输入的数据重新拷贝一份并只做少量的修改。

现实世界的有状态表现在如下的几个方面：
1. 程序调用的结果。
2. 服务组合下的上下文。
3. 服务的配置。

为了做出无状态的服务，需要把状态保存到其他的地方。比如，不太重要的数据可以放到Redis中，重要的数据可以放到MySQL中，或是像ZooKeeper/Etcd这样的高可用的强一致性的存储中，或是分布式文件系统中。

### 有状态的服务Stateful
无状态服务在程序Bug上和水平扩展上有非常优秀的表现，但是其需要把状态存放在一个第三方存储上，增加了网络开销，而在服务内的缓存需要在所有的服务实例上都有（因为每次请求不会都落在同一个服务实例上），这是比较浪费资源的。

有状态的服务有这些好处：
1. 数据本地化（Data Locality）。一方面状态和数据是本机保存，这方面不但有更低的延时，而且对于数据密集型的应用来说，这会更快。
2. 更高的可用性和更强的一致性。也就是CAP原理中的A和C。

无状态的服务需要把数据同步到不同的节点上，而有状态的服务通过Sticky Session做数据分片。

如何实现Sticky Session：
最简单的实现就是持久化的长连接。就算是HTTP协议也要用长连接，或是通过一个简单的哈希（hash）算法，比如通过uid求模的方式，走一致性哈希的玩法，也可以方便地做水平扩展。
但是长连接一般会有“反向压力（Back Pressure）”，节点的负载和数据并不会很均匀，如果服务端成了热点，那么久主动断连接很危险，需要客户端的配合，否则容易出Bug。
如果要做到负载和数据均匀的话，需要有一个元数据索引来映射后端服务实例和请求的对应关系，还需要一个路由节点根据元数据索引来路由，而这个元数据索引表会根据后端服务的压力来重新组织相关的映射。也可以把这个路由节点给去掉，让有状态的服务直接路由。做到这点需要直接配置，在节点启动时把其元数据读到内存中，但是这样一来增加或减少节点都需要重新配置，会导致其他节点也一同要重新读入。另一种比较好的做法是使用到Gossip协议，通过这个协议在各个节点之间互相散播消息来同步元数据，这样新增或减少节点，集群内部可以很容易重新分配。

### 服务状态的容错设计

在容错设计中，服务状态是一件非常复杂的事。尤其对于运维来说，因为要调度服务就要调度服务的状态，迁移服务的状态就需要迁移服务的数据。在数据量比较大的情况下变得尤为困难。

很多系统的高可用的设计都会采取数据在运行时就复制的方案，比如：ZooKeeper、Kafka、Redis 或是 ElasticSearch 等等。在运行时进行数据复制就需要考虑一致性的问题，所以，强一致性的系统一般会使用两阶段提交。这要求所有的节点都需要有一致的结果，这是 CAP 里的 CA 系统。而有的系统采用的是大多数人一致就可以了，比如 Paxos 算法，这是 CP 系统。即使是这样，当一个节点挂掉了以后，在另外一个地方重新恢复这个节点时，这个节点需要把数据同步过来才能提供服务。然而，如果数据量过大，这个过程可能会很漫长，这也会影响我们系统的可用性。

需要使用底层的分布式文件系统，对于有状态的数据不但在运行时进行多节点间的复制，同时为了避免挂掉，还需要把数据持久化在硬盘上，这个硬盘可以是挂载到本地硬盘的一个外部分布式的文件卷。这样当节点挂掉以后，以另外一个宿主机上启动一个新的服务实例时，这个服务可以从远程把之前的文件系统挂载过来。然后，在启动的过程中就装载好了大多数的数据，从而可以从网络其它节点上同步少量的数据，因而可以快速地恢复和提供服务。

## 补偿事务

### ACID和BASE

传统关系型数据库系统的事务都有ACID属性，即原子性（Atomicity）、一致性（Consistency）、隔离性（Isolation，又称独立性）、持久性（Durability）。

ACID
1. 原子性：
整个事务中的所有操作，要么全部完成，要么全部失败，不可能停滞在中间某个环节。事务在执行过程中发生错误，会被回滚（Rollback）到事务开始前的状态，就像这个事务从来没有执行过一样。
2. 一致性：
在事务开始之前和事务结束以后，数据库的完整性约束没有被破坏。
3. 隔离性：
两个事务的执行是互不干扰的，一个事务不可能看到其他事务运行时中间某一时刻的数据。两个事务不会发生交互。
4. 持久性：
在事务完成以后，该事务对数据库所做的更改便持久地保存在数据库之中，并不会被回滚。

对于分布式系统来说，尤其是微服务，这样的方式很难满足高性能要求。在分布式的服务架构中，一致性（Consistency）、可用性（Availability）、分区容忍性（Partition Tolerance），在现实中不能都满足，最多只能满足其中两个。

BASE
1. Basic Availability：基本可用。系统可以出现暂时不可用的状态，而后面会快速恢复。
2. Soft-state：软状态。是“有状态”和“无状态”的服务的一种中间状态。也就是说，为了提高性能，可以让服务暂时保存一些状态或数据，这些状态和数据不是强一致性的。
3. Eventual Consistency：最终一致性，系统在一个短暂的时间段内是不一致的，但最终整个系统看到的数据是一致的。

在分布式系统的世界里，故障是不可避免的，能做的就是把故障处理当成功能写入代码中，Design for Failure。 BASE的系统倾向于设计出更加有弹力的系统，这种系统的设计特点是，要保证在短时间内，就算是有数据不同步的风险，也应该允许新的交易可以发生，而后面在业务上将可能出现问题的事务给处理掉，以保证最终的一致性。

### 业务补偿

分布式系统当条件不满足，或是有变化的时候，需要从业务上做相应的整体事务的补偿。

如何进行业务补偿：
1. 需要将服务做成幂等性的，如果一个事务失败了或是超时了，需要不断地重试，努力地达到最终想要的状态。
2. 如果不能达到这个想要的状态，需要把整个状态恢复到之前的状态，如果有变化的请求，需要启动整个事务的业务更新机制。

好的业务补偿的标准：
1. 要能清楚地描述出要达到什么样的状态，以及如果其中的条件不满足，那么要回退到哪一个状态。这就是整个业务的起始状态定义。
2. 当整条业务跑起来的时候，可以串行或并行地做这些事。系统需要努力达到想要的状态；如果达不到，需要通过补偿机制回滚到之前的状态。这就是状态拟合。
3. 对于已经完成的事务进行整体修改，可以考虑成一个修改事务。

### 业务补偿的设计重点

业务补偿主要做：
1. 努力地把一个业务流程执行完成。
2. 执行不下去，需要启动补偿机制，回滚业务流程。

重点：
- 因为要把一个业务流程执行完成，需要这个流程中所涉及的服务方支持幂等性。并且在上游有重试机制。
- 为了维护和监控整个过程的状态，不要把这些状态放到不同的组件中，最好是一个业务流程的控制方来做这个事，也就是工作流引擎，需要高可用和稳定。
- 补偿的业务逻辑和流程不一定非得严格反向操作。有时候可以并行，有时候可以串行，可能会更简单。涉及业务正向流程的时候，也需要涉及业务的反向补偿流程。
- 业务补偿的业务逻辑是强业务相关的，很难做成通用的。
- 下层的业务方最好提供短期的资源预留机制。如果没有收到用户的支付，则释放库存，然后回滚到之前的下单操作，等待用户重新下单。

## 重试设计

### 重试的场景

认为这个故障是暂时的，而不是永久的。

### 重试的策略

重试设计需要设计重试最大值。在重试过程中，每一次重试失败时都应该休息一会儿再重试，这样可以避免因为重试过快而导致网络上的负担加重。

5种返回错误：
成功SUCCESS、维护NOT_READY、流控TOO_BUSY、没有资源NO_RESOURCE、系统错误SERVER_ERROR

### 重试设计的重点

1. 确定什么样的错误下需要重试。
2. 重试的时间和重试的次数。
3. 超过重试次数，或是一段时间，重试失去意义。需要使用熔断设计。
4. 重试需要考虑被调用方是否有幂等的设计。如果没有，重试是不安全的，可能会导致一个相同的操作被执行多次。
5. 重试的代码比较简单也比较通用，完全可以不用侵入到业务代码中。一个是代码级的，一个是Service Mesh的方式。
6. 把上下文暂存在本机或是数据库种，然后腾出资源来做别的事，过一会再回来把之前的请求从存储种捞出来重试。

## 熔断设计

熔断器模式可以防止应用程序不断地尝试执行可能会失败的操作，使得应用程序继续执行而不用等待修正错误，或者浪费CPU时间去等待长时间的超时产生。

熔断器可以使用状态机来实现，内部模拟以下几种状态。
- 闭合（Closed）状态：最近失败次数超过了在给定时间内允许失败的阈值，则切换到断开（Open）状态。此时开启了一个超时时钟，当该时钟超过了该时间，则切换到半断开（Half-Open）状态。该超时时间的设定是给了系统一次机会来修正导致调用失败的错误，以回到正常工作的状态。在Closed状态下，错误计数器是基于时间的。在特定的时间间隔内会自动重置。
- 断开（Open）状态：在该状态下，对应用程序的请求会立即返回错误响应，而不调用后端的服务。
- 半开（Half-Open）状态：允许应用程序一定数量的请求去调用服务。调用成功，可认为之前导致调用失败的错误已经修正，此时熔断器切换到闭合状态，同时将错误计数器重置。如果一定数量的请求有调用失败的情况，则认为导致之前调用失败的问题仍然能存在，熔断器切回到断开状态，然后重置计时器给系统一定的时间修正错误。半断开状态能够有效防止正在恢复种的服务被突然而来的大量请求再次拖垮。

https://static001.geekbang.org/resource/image/34/7f/34151c1a1caa1bd57a6fcdd3c92b7d7f.png?wh=529*477

实现熔断器模式使得系统更加稳定和有弹性，在系统从错误中恢复的时候提供稳定性，并且减少了错误对系统性能的影响。它快速地拒绝那些有可能导致错误的服务调用。如果熔断器设计模式在每次状态切换的时候会发出一个事件，这种信息可以用来监控服务的运行状态，能够通知管理员在熔断器切换到断开状态时进行处理。

### 熔断设计的重点

实现熔断器模式的时候，以下因素需要考虑：
1. 错误的类型。请求失败的原因有很多种，需要根据不同的错误情况来调整相应的策略。
2. 日志监控。监控使用熔断器保护服务的执行情况。
3. 测试服务是否可用。断开状态下，熔断器可以采用定期地ping一下远程服务的健康检查接口，来判断服务是否恢复，而不是使用计时器来自动切换到半开状态。好处是在服务恢复的情况下，不需要真实的用户流量就可以把状态从半开状态切回关闭状态。
4. 手动重置。对于失败操作的恢复时间是很难确定的，提供一个手动重置功能能够使得管理员可以手动地强制将熔断器切换到闭合状态。同样，如果受熔断器保护的服务暂时不可用，能够强制将熔断器设置为断开状态。
5. 并发问题。 相同的熔断器有可能被大量并发请求同时访问。熔断器的实现不应该阻塞并发的请求或增加每次请求调用的负担。最好使用一些无锁的数据结构，或是atomic的原子操作。
6. 资源分区。只对有问题的分区进行熔断，而不是整体。
7. 重试错误的请求被调用端支持幂等调用，否则会出现一个操作被执行多次的副作用。

## 限流设计

### 限流的策略

限流的目的是通过对并发访问进行限速，相关的策略一般是，一旦达到限制的速率，就会触发相应的限流行为。一般触发的限流行为如下：
1. 拒绝服务。把多出来的请求拒绝掉。
2. 服务降级。关闭或是把后端服务做降级处理。一种是把一些不重要的服务给停掉，把CPU、内存或是数据的资源让给更重要的功能；一种是不再返回全量数据，只返回部分数据。
3. 特权请求。把有限的资源分给重要的用户。
4. 延时处理。使用缓冲队列只是为了减缓压力，一般用于应对短暂的峰刺请求。
5. 弹性伸缩。动用自动化运维的方式对相应的服务做自动化的伸缩。

### 限流的实现方式

1. 计数器方式：
最简单的限流算法就是维护一个计数器Counter，当一个请求来时，就做加一操作，当一个请求处理完后就做减一操作。如果这个Counter大于某个数，那么就开始拒绝请求以保护系统的负载。

2. 队列算法：
在这个算法下，请求的速度可以是波动的，而处理的速度则是非常均速的。这个算法比较像FIFO。
https://static001.geekbang.org/resource/image/c8/3d/c8f774f88ab8a4b72378971263c0393d.png?wh=860*175

具有优先级的队列，处理时先处理高优先级的队列，然后再处理低优先级的队列。
https://static001.geekbang.org/resource/image/de/80/de51d6fc68df3d8c808b84e4bc455580.png?wh=858*320

有优先级的队列可能会导致低优先级队列长时间得不到处理。为了避免低优先级的队列被饿死，一般来说是分配不同比例的处理时间到不同的队列上，于是有了带权重的队列。
https://static001.geekbang.org/resource/image/c7/54/c775345e3b8f599e26a4d7f64941cd54.png?wh=858*366

3. 漏斗算法Leaky Bucket
https://static001.geekbang.org/resource/image/95/00/95326ea1624d4206a26ff275b39efc00.png?wh=862*587

一般来说，“漏斗”是一个队列来实现的，当请求过多时，队列就会开始积压请求，如果队列满了，就会开始拒绝请求。当请求的数量过多时，就会有一个sync backlog的队列来缓冲请求，或是TCP的滑动窗口也是用于流控的队列。
https://static001.geekbang.org/resource/image/d4/a0/d4b8b6ceb8de4400dfc97f3ff0feeaa0.png?wh=858*297

4. 令牌桶算法 Token Bucket
关于令牌桶算法，主要是有一个中间人。在一个桶内按照一定的速率放入一些token，然后处理程序要处理请求时，需要拿到token，才能处理；如果拿不到，则不处理。
https://static001.geekbang.org/resource/image/99/f0/996b8d60ed90c470ce839f8826e375f0.png?wh=808*481

漏斗算法中，处理请求是以一个常量和恒定的速度处理的，而令牌桶算法则是在流量小的时候累积，流量大的时候一次发出队列里有的请求，而后就受到令牌桶的流控限制。

### 基于响应时间的动态限流
上面算法都需要设置一个确定的限流值。这就要求每次发布服务时都做响应的性能测试，找到系统最大的性能值。

难以获得性能值的原因：
- 实际情况下，很多服务会依赖于数据库，所以不同的用户请求，会对不同的数据集进行操作。
不同的API有不同的性能。要在线上为每一个API配置不同的限流值，难度高且难管理。 
- 现在的服务都是能自动化伸缩，不同大小的集群的性能也不一样。动态调整限流的阈值，很难做得到。

动态限流的方式不再设定一个特定的流控值，而是能够动态地感知系统的压力来自动化地限流。
这方面设计的典范是TCP协议的拥塞控制的算法。TCP使用RTT-Round Trip Time来探测网络的延时和性能，从而设定相应的“滑动窗口”的大小，以让发送的速率和网络的性能相匹配。

### 限流的设计要点

限流的目的：
1. 为了向用户承诺SLA。保证我们的系统在某个速度下的响应时间以及可能性。
2. 用来阻止在多租户的情况下，某一用户把资源耗尽而让所有的用户都无法访问的问题。
3. 为了应对突发的流量。
4. 节约成本。不会为了一个不常见的尖峰来把我们的系统扩容到最大的尺寸。而是在有限的资源下能够承受比较高的流量。

设计上的其他考量：
- 限流应该是在架构的早期考虑。                                   
- 限流模块性能必须好，而且对流量的变化也是非常灵敏的，否则太过迟钝的限流，系统早因为过载而挂掉了。
- 限流应该有个手动的开关，在应急的时候可以手动操作。
- 当限流发生时，应该有个监控事件通知。
- 当限流发生时，对于拒掉的请求，应该返回一个特定的限流错误码。可以和其他错误区分开来，而客户端看到限流，可以调整发送速度，或是走重试机制。
- 限流应该让后端的服务感知到。

## 降级设计

降级（Degradation）是为了解决资源不足和访问量过大的问题。当资源和访问量出现矛盾的时候，在有限的资源下，为了能够抗住大量的请求，需要对系统进行降级操作。

降级需要牺牲掉的东西：
1. 降低一致性。从强一致性变成最终一致性。
2. 停止次要功能。停止访问不重要的功能，从而释放出更多的资源。
3. 简化功能。把一些功能简化掉。

### 降低一致性

对于降低一致性，把强一致性变成最终一致性的做法可以有效地释放资源，并且让系统运行得更快，从而可以扛住更大的流量。一般来说，一种是简化流程的一致性，一种是降低数据的一致性。

降低数据的一致性一般来说会使用缓存的方式，或是直接就去掉数据。对于缓存来说，可以有效地降低数据库的压力，把数据库的资源交给重要的业务，这样就能让系统更快速地运行。对于降级后的系统，不再通过数据库获取数据，而是通过缓存获取数据。功能降级中，一般使用Cache Aside模式或是Read Through模式。

https://static001.geekbang.org/resource/image/bd/c4/bdf7522a231ec2c1136a70f07db0c5c4.png?wh=864*270

- 失效：应用程序先从cache取数据，如果没有得到，则从数据库中取数据，成功后，放到缓存中。
- 命中：应用程序从cache中取数据，取到后返回。
- 更新：先把数据存到数据库中，成功后，再让缓存失效。

### 停止次要的功能

停止次要功能就是把一些不重要的功能给暂时停止掉，让系统释放出更多的资源。等待峰值过去再把功能给恢复。

### 简化功能

1. 从缓存中返回数据。
2. 一个API会有两个版本，一个版本返回全量数据，另一个版本只返回部分或最小的可用的数据。这样可以释放更多的数据资源。而商品信息或文章信息可以放在缓存中，这样又能释放出更多的资源给交易系统这样的需要更多数据库资源的业务使用。

### 降级设计的要点

1. 业务的深度理解。
2. 读操作，缓存解决；写操作，异步处理。
3. 降级功能的开关是可配置开关。
4. 后端服务可感知。

## 弹力设计总结

### 弹力设计总图

1. 服务不能是单点
2. 需要在架构中冗余服务，也就是说有多个服务的副本。需要使用到的具体技术有：
- 负载均衡 + 服务健康检查-可以使用像Nginx或HAProxy这样的技术；
- 服务发现 + 动态路由 + 服务健康检查，比如Consul或Zookeeper；
- 自动化运维，Kubernetes服务调度、伸缩和故障迁移。
3. 需要隔离业务，要隔离服务就需要对服务进行解耦和拆分，这需要使用到以前的相关技术。
- bulkheads模式：业务分片、用户分片、数据库拆分。
- 自包含系统：所谓自包含的系统是从单体到微服务的中间状态，其把一组密切相关的微服务给拆分出来，只需要做到没有外部依赖。
- 异步通讯：服务发现、事件驱动、消息队列、业务工作流。
- 自动化运维：需要一个服务调用链和性能监控的监控系统。
4. 要进行能让整个架构接受失败的相关处理设计，也就是容错设计。会用到下面的这些技术。
- 错误方面：调用重试 + 熔断 + 服务的幂等性设计。
- 一致性方面：强一致性使用两阶段提交、最终一致性使用异步通讯方式。
- 流控方面：使用限流 + 降级技术。
- 自动化运维方面：网关流量调度，服务监控。

https://static001.geekbang.org/resource/image/a7/2f/a7f9e41b0457326e08ffc93e319d352f.jpg?wh=2085x1473

三大块：
1. 冗余服务。通过冗余服务的复本数可以消除单点故障。需要服务发现，负载均衡，动态路由和健康检查四个功能或组件。
2. 服务解耦。通过解耦可以做到把业务隔离开，不让服务受影响，有更好的稳定性。在水平层面，需要把业务或用户分片分区（业分做隔离，用户做多租户）。在垂直层面，需要异步通讯机制。因为应用被分解成一个个服务，所以在服务的编排和聚合上，需要有工作流（像Spring的Stream或Akka的flow或是AWS的Simple Workflow）来把服务给串联起来。而一致性的问题又需要业务补偿机制来做反向交易。
3. 服务容错。服务容错方面，需要有重试机制，重试机制会带来幂等操作，对于服务保护来说，熔断，限流，降级都是为了保护整个系统的稳定性，并在可用性和一致性方面在出错的情况下做一部分妥协。

### 弹力设计开发和运维

对于运维工具，至少需要两个系统：
1. 像APM一样的服务监控。
2. 服务调度的系统，如Docker + Kubernetes。

Deploying Microservices: Spring Cloud vs Kubernetes

https://static001.geekbang.org/resource/image/35/f4/35cd0722f99f91c904944ac1bbdd56f4.png?wh=862*339

Spring Cloud和Kubernetes都是为了微服务而生，前者偏开发，后者偏运维。
- Spring Cloud有一套丰富且集成良好的Java库，作为应用栈的一部分解决所有运行时问题。因此，微服务本身可以通过库和运行时代理解决客户端服务发现、负载均衡、配置更新、统计跟踪等。工作模式就像单实例服务集群。
- Kubernetes不是针对语言的，而是针对容器的。Kubernetes提供了配置管理、服务发现、负载均衡、跟踪、统计、单实例、平台级和应用栈之外的调度工作。该应用不需要任何客户端逻辑的库或代理程序，可以用任何语言编写。

https://static001.geekbang.org/resource/image/dc/af/dcab89f031d1a7083b4f0b3091873caf.png?wh=539*818

https://static001.geekbang.org/resource/image/41/6a/41e9f7a084e6c81fcb3bb42d43b0076a.png?wh=864*502

红色的是运维层面的和Spring Cloud和Kubernetes不相关的，绿色的Spring Cloud提供的开发框架，蓝色的是Kubernetes相关的重要功能。

# 管理设计

## 分布式锁

锁的设计原则
1. 互斥：同一时刻临界区中最多存在一个线程。
2. 前进（Progress）：如果一个线程想要进入临界区，那么最终会成功。
3. 有限等待：如果一个线程i处于入口区，那么在i的请求被接受之前，其它线程进入临界区的时间是有限制的。尝试获取，减少上下文切换，提升效率。
4. 无忙等待（可选）：如果一个进程在等待进入临界区，那么它可用进入之前被挂起。

在多线程情况下访问一些共享资源需要加锁，不然就会出现数据被写乱的问题。分布式的锁服务需要有以下几个特点。
- 安全性（Safety）：在任意时刻，只有一个客户端可以获得锁（排他性）。
- 避免死锁：客户端最终一定可以获得锁，即使锁住某个资源的客户端在释放锁之前崩溃或者网络不可达。
- 容错性：只要锁服务集群中的大部分节点存活，Client就可以进行加锁解锁操作。

### Redis的分布式锁服务

https://redis.io/topics/distlock

只有在某个key不存在的情况下才能设置（set）成功该key。这就可以让多个进程并发去设置同一个key，只有一个进程能设置成功。而其它的进程因为之前有人把key设置成功了，而导致失败。

关于 value 的生成，官方推荐从 /dev/urandom 中取 20 个 byte 作为随机数。或者采用更加简单的方式，例如使用 RC4 加密算法在 /dev/urandom 中得到一个种子（Seed），然后生成一个伪随机流。也可以采用更简单的方法，使用时间戳 + 客户端编号的方式生成随机数。Redis 的官方文档说：“这种方式的安全性较差一些，但对于绝大多数的场景来说已经足够安全了”。

### 分布式锁服务的一个问题

https://static001.geekbang.org/resource/image/93/89/937d9975899662d90a96f4cd70580d89.png?wh=864*387

解决上述问题，需要引入fence（栅栏）技术。一般来说，这就是乐观锁机制，需要一个版本号排它。

https://static001.geekbang.org/resource/image/ce/c3/ce3454e9a8bbfe4628899391c003a5c3.png?wh=864*383

从图中可以看到：
1. 锁服务需要有一个单调递增的版本号。
2. 写数据的时候，也需要带上自己的版本号。
3. 数据库服务需要保存数据的版本号，然后对请求做检查。

如果使用ZooKeeper做锁服务，可以使用zxid或znode的版本号来做这个fence版本号。

### 从乐观锁到CAS

https://static001.geekbang.org/resource/image/95/41/9557fb5b7269eb5d7d53568298803141.png?wh=847*270
使用数据版本（Version）记录机制，即为数据增加一个版本标识，一般是通过为数据库表增加一个数字类型的“version”字段来实现的。当读取数据时，将version字段的值一同读出，数据每更新一次，对此version值加一。如果使用版本号，或是fence token这种方式，就不需要使用分布式锁服务。
这种fence token的方法，在数据库那边一般会用timestamp时间戳。也是在更新提交的时候检查当前数据库中数据的时间戳和自己更新前取到的时间戳进行对比，一致就是OK，否则就是版本冲突。

计算机汇编指令中原子操作CAS（Compare And Swap），大量无锁的数据结构都需要用到这个。

### 分布式锁设计的重点

一般情况下，可以使用数据库、Redis或ZooKeeper来做分布式锁服务，这几种方式都可以用于实现分布式锁。

分布式锁的特点是，保证在一个集群中，同一个方法在同一时间只能被一台机器上的一个线程执行。这就是分布式互斥。所以在做某个事的时候，要去一个服务上请求一个标识。如果请求到了，就可以操作，操作完后，把这个标识还回去。

分布式锁服务可以考虑的几个设计：
1. 需要给一个锁被释放的方式，以避免请求者不把锁还回来，导致死锁的问题。Redis使用超时时间，ZooKeeper可以依靠自身的sessionTimeout来删除节点。
2. 分布式锁服务应该是高可用的，而且是需要持久化的。
3. 要提供非阻塞方式的锁服务。
4. 考虑锁的可重入性。

## 配置中心

### 配置中心的设计

软件配置的区分有静态配置和动态配置

静态配置：
在软件启动时的一些配置，运行时基本不会进行修改，也可以理解为是环境或软件初始化时需要用到的配置。

动态配置的管理：
1. 按运行环境分。一般来说，会有开发环境、测试环境、预发环境、生产环境。
2. 按依赖区分。一种是依赖配置，一种是不依赖的内部配置。
3. 按层次分。配置同样可以分成laaS、PaaS、SaaS三层。基础层的配置是操作系统的配置，中间平台层的配置是中间件的配置，上层软件层的配置是应用自己的配置。

### 配置中心的模型

软件配置上说，每个配置项就是key/value模型。
https://static001.geekbang.org/resource/image/5a/b7/5aeb4055738bd15188a007ccbbbc38b7.png?wh=864*1075

### 配置中心的架构

https://static001.geekbang.org/resource/image/c0/b9/c0dfc0eca560dce3b6de8dcc92a92ab9.jpg?wh=1968x753

1. 为什么需要一个变更通知的组件，而不是让配置中心直接推送？
分布式环境下，服务器太多，推送不太现实，而采用一个Pub/Sub的通知服务可以让数据交换经济一些。

2. 为什么不直接Pub数据过去，还要订阅方反向拉数据？
好处一方面是API可以校验请求者的权限，另一方面是需要调用配置中心的基本API，如下载最新的证书。还有就是服务启动时需要从服务中心拉一份配置下来。

3. 配置变更控制器部署在哪里？是在每个服务器上，还是在一个中心的地方？
变更配置有很多步骤，这些步骤算是一个事务。为了执行效率更好，事务成功率更大，建议把配置变更的控制放在每一台主机上。

4. 平台层的配置变更，有的参数是在服务启动的命令行上，这个怎么变更呢？
命令行上的参数需要通过Shell环境变量做成配置项，然后通过更改系统环境变量，并重启服务达到配置变更。

5. 操作系统的配置变更和平台层的配置变更最好模块化掉，就像云服务中的不同尺寸的主机型号一样。这样有利于维护和减少配置的复杂性。

6. 应用服务配置更新的标准化。因为一个公司的应用由不同的团队完成，配置会因为应用的属性不同而不一样。为了方便管理，最好有统一的配置更新。但服务配置方式不一样。有以下解决方法：
- 通过一个开发框架或SDK的方式来解决，也就是应用代码找这个SDK来要配置，并通过observer模式订阅配置修改的事件，或是直接提供配置变更的Admin的API。好处在于在开发期标准化，并可以规范开发；不好的是，耦合语言。
- 通过一个标准应用运维脚本，让应用方自己来提供变更时的脚本动作。这种方式虽然通过运维的方式标准化掉配置变更的接口，就可以通过一个配置控制器来统一操作各个应用变更，但是在这个脚本中各个应用方依然使用着各种不同的方式来变更配置。好处是不耦合语言，灵活，但但对于标准化的建设可能不利，而且使用或者调用脚本是Bug很多的东西，容易出问题。
- 或是结合上述两种方案，不使用开发阶段的SDK方式嵌入到应用服务中，而是为每个应用服务单独做一个Agent。这个Agent对外以Admin API的方式服务，后面则适配应用的配置变更手段，如更新配置文件，或者调用应用的API等。

### 配置中心的设计重点

配置中心主要的用处是统一和规范化管理所有的服务配置，也算是一种配置上的治理活动。所以，配置中心的设计重点应该放在如何统一和标准化软件的配置项，其还会涉及到软件版本、运行环境、平台、中间件等一系列的配置参数。

配置有控制面上的配置和业务逻辑面上的配置，控制面上的配置最好能标准统一。

配置更新的时候是一个事务处理，需要考虑事务的问题，如果变更不能继续，需要回滚到上个版本的配置。配置版本最好和软件版本对应上。

配置更新控制器，需要应用服务的配合，最好由统一的开发框架搞定。

配置更新控制器还担任服务启动的责任，由配置更新控制器来启动服务。这样，配置控制器会从配置中心拉取所有的配置，更新操作系统，设置好启动时用的环境变量，并更新好服务需要的配置文件，然后启动服务。

## 边车模式

### 边车模式设计
边车有点像一个服务的Agent，这个服务所有对外的进出通讯都通过这个Agent完成。但是需要保证Agent要和应用程序一起创建，一起停用。

边车模式可以叫做搭档模式、伴侣模式、跟班模式。编程的本质就是将控制和逻辑分离和解耦，而边车模式也是异曲同工，同样是让我们在分布式架构中做到逻辑和控制分离。

对于监视、日志、限流、熔断、服务注册、协议转换等功能，其实都是大同小异，甚至是做成标准化的组件和规模的。一般有两种方式：
1. 通过SDK、Lib或Framework软件包方式，在开发时与真实的应用服务集成起来。
2. 另一种是通过像Sidecar这样的方式，在运维时与真实的应用服务集成起来。

两种方法各有优缺点：
- 以软件包的方式可以和应用密切集成，有利于资源的利用和应用的性能，但是对应用有侵入，而且受应用的编程语言和技术限制。同时当软件包升级的时候，需要重新编译并重新发布应用。
- 以Sidecar的方式，对应用服务没有侵入性，而且不用受应用服务的语言和技术的限制，而且可以做到控制和逻辑的分开升级和部署。但是这样一来，增加了每个应用服务的依赖性，也增加了应用的延迟，并且也会大大增加管理、托管、部署的复杂度。但对于一些老系统如C、COBOL，需要改变成分布式系统，需要对其进行协议的改造以及进行相应的监控和管理因为无侵入性的原因适用性强。Sidecar服务在逻辑上和应用服务部署在一个结点中，和应用服务有相同的声明周期。对于应用服务的每个实例，都会有一个Sidecar的实例。
- Sidecar可以帮助服务注册到相应的服务发现系统，并对服务做相关的健康检查。如果服务不健康，可以从服务发现系统中把服务实例移除。
- 当应用服务要调用外部服务时，Sidecar可以帮助从服务发现中找到相应外部服务的地址，然后做服务路由。
- Sidecar接管了进出的流量，就可以做相应的日志监视、调用链跟踪、流控熔断......
- 服务控制系统可以通过控制Sidecar来控制应用服务，如流控、下线等。

https://static001.geekbang.org/resource/image/e3/f7/e30300b16a8fe0870ebfbec5a093b4f7.png?wh=864*441

### 边车设计的重点

边车模式重点解决的问题：
1. 控制和逻辑的分离。
2. 服务调用中上下文的问题。

熔断、路由、服务发现、计量、流控、监视、重视、幂等、鉴权等控制面上的功能，以及其相关的配置更新，本质上讲，和服务的关系不打。但是传统的工程做法是在开发层面完成这些功能，就会导致各种维护上的问题，而且还会受到特定语言和编程框架的约束和限制。而随着系统架构的复杂化和扩张，需要更统一地管理和控制这些控制面上的功能，所以传统的在开发层面上完成控制面的管理会变得非常难以管理和维护。

边车模式工程实现上的注意点：
- 进程间通讯机制是这个设计模式的重点，不要使用任何对应用服务有侵入的方式。最好的方式就是网络远程调用的方式。
- 服务协议方面，也使用标准统一的方式。这里有两层协议，一个是Sidecar到service的内部协议，另一个是Sidecar到远端Sidecar或service的外部协议。对于内部协议，需要尽量靠近和兼容本地service的协议；对于外部协议，需要尽量使用更为开放更为标准的协议。但无论哪种，都不应该使用与语言相关的协议。
- 使用这样的模式，需要在服务的整体打包、构建、部署、管控、运维上设计好。使用Docker容器方面的技术可以全面降低复杂度。
- Sidecar中所实现的功能应该是控制面上的东西，而不是业务逻辑上的东西，所以不要把业务逻辑设计到Sidecar中。
- 小心在Sidecar中包含通用功能可能带来的影响。
- 还要考虑允许应用服务和Sidecar的上下文传递的机制。或是Sidecar告诉应用服务限流发生，或是远程服务不可用等信息，这样可以让应用服务和Sidecar配合得更好。

Sidecar适用的场景：
- 一个比较明显的场景是对老应用系统的改造和扩展。
- 另一个是对由多种语言混合出来的分布式服务系统进行管理和扩展。
- 其中的应用服务由不同的供应商提供。
- 把控制和逻辑分离，标准化控制面上的动作和技术，从而提高系统整体的稳定性和可用性，也有利于分工。

Sidecar不适用的场景：
- 架构并不复杂的时候，不需要使用这个模式，直接使用API Gateway或者Nginx和HAProxy等即可。
- 服务间的协议不标准且无法转换。
- 不需要分布式的架构。

## 服务网格

Service Mesh
这个服务网络专注于处理服务和服务间的通讯。主要特点有：
- 是一个基础设施。
- 是一个轻量的服务通讯的网络代理。
- 对于应用服务来说是透明无侵入的。
- 对于解耦和分离分布式系统架构中控制层面上东西。

Service Mesh就像是网络七层模型中的第四层TCP协议。其把底层的那些非常难控制的网络通讯方面的控制面的东西都管了（如：丢包重传、拥塞控制、流量控制），而更为上面的应用层的协议，只需要关心自己业务应用层上的事。

Lstio的架构
https://static001.geekbang.org/resource/image/1a/f2/1a579db1c95608588052b167e68836f2.png?wh=827*443

https://philcalcado.com/2017/08/03/pattern_service_mesh.html
演化路径：
1. 最原始的两台主机间的进程直接通信。
2. 分离出网络层，服务间的远程通信，通过底层的网络模型完成。
3. 两边的服务在接收的速度上不一致，需要应用层中实现流控。
4. 流控模块基本可以交给网络层实现，于是TCP/IP成了最主要的网络协议。
5. 分布式系统中的谬论。需要在分布式系统中设置“弹力设计”，于是在更上层加入像限流、熔断、服务发现、监控等功能。
6. 弹力设计的模式都是可以标准化的。将这些模式写成SDK/Lib/Framework，在开发层面上很容易地集成到应用服务中。
7. SDK\Lib\Framework不能够跨编程语言。有变动需要重新编译重新发布服务，应该有一个专门的层来干这事，于是出现了Sidecar。
8. Sidecar集群成了Service Mesh。
9. Sidecar组成了一个平台。

## 网关模式

### 网关模式设计
网关需要以下功能：
1. 请求路由。因为不再是Sidecar，所以网关一定要有请求路由的功能。调用端可以在不需要知道自己需要用到的其它服务的地址，全部统一地交给Gateway来处理。
2. 服务注册。为了能够代理后面的服务，并把请求路由到正确的位置上，网关应该有服务注册功能，也就是后端的服务实例可以把其提供服务的地址注册、取消注册。一般来说，注册也就是注册一些API接口，这样Gateway就可以根据接收到的请求中的信息来决定路由到哪一个后端的服务上。
3. 负载均衡。因为一个网关可以接收多个服务实例，所以网关还需要在各个对等的服务实例上做负载均衡策略。简单点就是直接Round-Robin轮询，复杂点的可以设置上权重进行分发，再复杂一点还可以做到session粘连。
4. 弹力设计。网关还可以把弹力设计中的那些异步、重试、幂等、流控、熔断、监视等都可以实现进去。这样，同样可以像Service Mesh那样人，让应用服务只关心自己的业务逻辑而不是控制逻辑（控制面）。
5. 安全方面。SSL加密及证书管理、Session验证、授权、数据校验，以及对请求源进行恶意攻击的防范。错误处理越靠前的位置就是越好，所以网关可以做到一个全站的接入组件来对后端的服务进行保护。

除此之外，还可以做更多有趣的事情：
1. 灰度发布。网关完全可以做到对相同服务不同版本的实例进行导流，还可以收集相关的数据。
2. API聚合。使用网关可以将多个单独请求聚合成一个请求。在微服务体系的架构中，因为服务变小，明显的问题是，客户端可能需要多次请求才能得到所有的数据。这样一来，客户端与后端之间的频繁通信会对应用程序的性能和规模产生非常不利的影响。因此可以让网关帮客户端请求多个后端的服务，然后把后端服务的响应结果拼装起来，回传给客户端。
3. API编排。同样在微服务的架构下，要走完一个完整的业务流程，需要调用一系列API，就像一种工作流一样，这个事完全可以通过网页来编排这个业务流程。可以通过一个DSL来定义和编排不同的API，也可以通过像AWS Lambda服务那样的方式来串联不同的API。

### Gateway、Sidecar和Service Mesh
网关、边车和Service Mesh是非常像的三种设计模式。

Sicecar的方式用来改造已有服务，可以适配应用服务，成为应用服务进出请求的代理。这样就可以干很多对于业务方完全透明的事情了。

当Sidecar在架构中越来越多时，需要对Sidecar进行统一的管理。于是为Sidecar增加一个全局的中心控制器，就出现了Service Mesh。在中心控制器出现以后，非业务功能的东西全部实现在Sidecar和Controller中，于是就成了网格。业务方只需要把服务往网格中一放就好，与其它服务的通讯、服务的弹力等都不用管，像服务的PaaS平台。

Service Mesh的架构和部署太过复杂，为了简化架构的复杂度，Sidecar的粒度可以变更。
Gateway只负责进入的请求，不像Sidecar还需要负责对外的请求。因为Gateway可以把一组服务给聚合起来，所以服务对外的请求可以交给对手服务的Gateway。于是只需要用一个负责进入请求的Gateway来简化需要同时负责进出请求的Sidecar的复杂度。

### 网关的设计重点

1. 高性能。技术上不应该成为性能的瓶颈。对于高性能，最好使用高性能的编程语言来实现，如C、C++、Go和Java。网关对后端的请求，以及对前端的请求的服务一定要使用异步非阻塞的I/O来确保后端延迟不会导致应用程序中出现性能问题。C和C++可以参看Linux下的epoll和Windows的I/O Completion Port的异步IO模型，Java下如Netty、Vert.x、Spring Reactor的NIO框架。
2. 高可用。所有的流量或调用经过网关，因为必须成为高可用的技术组件，它的稳定直接关系到所有服务的稳定。网关如果没有设计，就会变成一个单点故障。因此一个好的网关至少做到以下几点：
- 集群化。网关要成为一个集群，最好可以自己组成一个集群，并可以自己同步集群数据，而不需要依赖于一个第三方系统来同步数据。
- 服务化。网关还需要做到在不间断的情况下修改配置，一种是像Nginx reload配置那样，可以做到不停服务，另一种是最好做到服务化，即有自己的Admin API来在运行时修改自己的配置。
- 持续化。比如重启，就是像Nginx那样优雅地重启。有一个主管请求分发的主进程。当需要重启时，新的请求被分配到新的进程中，而老的进程处理完正在处理的请求后就退出。
3. 高扩展。因为网关需要承接所有的业务流量和请求，所以包含一定的业务逻辑，但业务逻辑是多变和不确定的。

在运维方面网关的设计原则：
1. 业务松耦合，协议紧耦合。在业务设计上，网关不应与后面的服务之间形成服务耦合，也不应该有业务逻辑。网关应该是在网络应用层上的组件，不应该处理通讯协议体，只应该解析和处理通讯协议头。另外，除了服务发现外，网关不应该有第三方服务的依赖。
2. 应用监视，提供分析数据。网关上需要考虑应用性能的监控，除了有相应后端服务的高可用的统计之外，还需要使用Tracing ID实施分布式链路跟踪，并统计好一定时间内每个API的吞吐量、响应时间和返回码，以便启动弹力设计中的相应策略。
3. 用弹力设计保护后端服务。网关上一定要实现熔断、限流、重试和超时等弹力设计。如果一个或多个服务调用花费的时间过长，那么可以接受超时并返回一部分数据。或是返回一个网关里的缓存的上一次成功请求的数据。
4. DevOps。网关这个组件关键，需要通过DevOps将发生故障的概率降到最低。这个软件需要经过精良的测试，包括功能和性能的测试，还有浸泡测试，还需要有一系列自动化运维的管控工具。

整体架构方面的注意项：
1. 不要在网关中的代码里内置聚合后端服务的功能，而应考虑将聚合服务放在网关核心代码之外。可以使用Plugin的方式，也可以放在网关后面形成一个Serverless服务。
2. 网关应该靠近后端服务，并和后端服务使用同一个内网，这样可以保证网关和后端服务调用的低延迟，并可以减少很多网络上的问题。网关处理的静态内容应该靠近用户（应该放在CDN上），而网关和此时的动态服务应该靠近后端服务。
3. 网关也需要做容量扩展，所以需要成为一个集群来分担前端带来的流量。这一点，要么通过DNS轮询的方式实现，要么通过CDN来做流量调度，或者通过更为底层的性能更高的负载均衡设备。
4. 对于服务发现，可以做一个时间不长的缓存，这样不需要每次请求都查一下相关的服务所在的地方。如果系统不复杂，可以考虑把服务发现的功能直接集成进网关中。
5. 为网关考虑bulkhead设计方式。用不同的网关服务不同的后端服务，或是用不同的网关服务前端不同的客户。

网关是为用户请求和后端服务的桥接装置，所以需要考虑一些安全方面的事宜。
1. 加密数据。可以把SSL相关的证书放到网关上，由网关做统一的SSL传输管理。
2. 校验用户的请求。基本的用户验证可以放在网关上做。如果协议体是标准的，那么可以干；另一方面，对于解析协议所带来的性能问题，需要做相应的隔离。
3. 检测异常访问。网关需要检测一些异常访问。

## 部署升级策略

服务部署的模式有如下几种：
- 停机部署（Big Bang / Recreate）：把现有版本的服务停机，然后部署新的版本。
- 蓝绿部署（Blue / Green /Stage）：部署好新版本后，把流量从老服务那边切过来。
- 滚动部署（Rolling Update / Ramped）：一点一点地升级现有的服务。
- 灰度部署（Canary）：把一部分用户切到新版本上来，然后看一下有没有问题。如果没有问题就继续扩大升级，直到全部升级完成。
- AB测试（A/B Testing）：同时上线两个版本，然后做相关的比较。

https://static001.geekbang.org/resource/image/08/75/08492dde28724d6f0a46ef89b0aec275.jpg?wh=1563x1173

### 停机部署：
简单地把现有版本的服务停机，然后部署新的版本。优点在于部署过程中不会出现新老版本同时在线的情况，所有状态完全一致。停机部署主要是为了新版本的一致性问题。缺点在于会停机对用户影响大，这种部署方式需要事前挂公告，选择一个用户访问少的时间段来做。

### 蓝绿部署：
蓝绿部署与停机部署最大的不同是，其在生产线上部署相同数量的新服务，然后当新的服务测试确认OK后，把流量切换到新的服务这边来。蓝绿部署比停机部署好的地方是无需停机。优点是没有停机，实时发布和升级，也避免有新旧版本同时在线的问题，在物理机时代有使用双倍资源的问题。缺点是如果服务中有状态，比如缓存，停机部署和蓝绿部署都会有问题。

### 滚动部署：
滚动部署策略是指通过逐个替换应用的所有实例，来缓慢发布应用的一个新版本。通常过程如下：在负载调度后有个版本A的应用实例池，一个版本B的实例部署成功，可以响应请求时，该实例被加入到池中。然后，版本A的一个实例从池中删除并下线。

同样存在一些部署的问题：
- 在发布过程中，会出现新老两个版本同时在线的情况，同一用户的请求可能在新老版中切换而导致问题。
- 新版程序没有在生产线上经过验证就上线了。
- 整个过程中，生产环境处于一个新老更替的中间状态，如果有问题要回滚麻烦。
- 如果在升级过程中，需要做别的一些运维工作，还需要判断哪些结点是老版本的，哪些是新版本的。
- 因为新老版本的代码同时在线，所以其依赖的服务需要同时处理两个版本的请求，这可能会带来兼容性问题。
- 无法让流量在新老版本中切换。

### 灰度部署（金丝雀）
灰度部署是指逐渐将生产环境流量从老版本切换到新版本。通常流量是按比例分配的。

除了切流量外，对于多租户的平台，例如云计算平台，灰度部署也可以将一些新的版本先部署到一些用户上，如果没有问题，扩大部署，直到全部用户。一般的策略是，从内部用户开始，然后是一般用户，最后是大客户。这个技术大多数用于缺少足够测试，或者缺少可靠测试，或者对新版本的稳定性缺乏信心的情况下把一部分用户切到新版上来，然后看一下有没有问题。如果没有问题就继续扩大升级，直到全部升级完成。

### AB测试
AB测试和蓝绿部署或是金丝雀灰度部署完全不一样。

AB测试是同时上线两个版本，然后做相关的比较。它是用来测试应用功能表现的方法，例如可用性、受欢迎程度、可见性等。

蓝绿部署是为了不停机，灰度部署是对新版本的质量没信心，AB测试是对新版的功能没信心。侧重点分别是质量和功能。

对于灰度发布或是AB测试可以使用下面的技术来选择用户：
- 浏览器cookie。
- 查询参数。
- 地理位置。
- 技术支持，如浏览器版本、屏幕尺寸、操作系统等。
- 客户端语言。

# 性能设计

## 缓存

分布式系统中最耗性能的地方就是最后端的数据库。

数据库四种操作（select、update、insert和delete）中的三个写操作insert、update和delete不太会出现问题。一般select是出现性能问题最大的地方。一方面，select会有很多像join、group、order、like等这样丰富的语义，这些语义非常耗性能；另一方面，大多数应用都是读多写少，所以加剧了慢查询的问题。

分布式系统中远程调用会消耗很多资源，因为网络开销会导致整体的响应时间下降。为了挽救这样的性能开销，在业务允许的情况（不太需要太实时的数据）下，使用缓存是非常必要的事情。另一方面，缓存在今天的移动互联网中是必不可少的一部分。

缓存是提高性能最耗的方式，一般来说缓存有以下三种模式：
1. Cache Aside更新模式
具体逻辑如下：
- 失效：应用程序先从Cache取数据，如果没有得到，则从数据库中取数据，成功后，放到缓存中。
- 命中：应用程序从Cache中取数据，取到后返回。
- 更新：先把数据存到数据库中，成功后，再让缓存失效。
https://static001.geekbang.org/resource/image/0a/d4/0a39fbce98c0d43e15b56b0ed09099d4.png?wh=625*195
https://static001.geekbang.org/resource/image/e0/94/e0ecbc94d474f7bd0c8eb53dfd8bde94.png?wh=625*191

应用代码需要维护两个数据存储，一个是缓存（cache），一个是数据库（repository）。

2. Read/Write Through 更新模式
更新数据库（repository）的操作由缓存自己代理了。可以理解为应用认为后端就是一个单一的存储，而存储自己维护自己的Cache。
- Read Through套路就是在查询操作中更新缓存，也就是说当缓存失效的时候（过期或LRU换出），Cache Aside是由调用方负责把数据加载入缓存，而Read Through则用缓存服务自己来加载，从而应用方是透明的。
- Write Through套路和Read Through相仿，不过是在更新数据时发生。当有数据更新的时候，如果没有命中缓存，直接更新数据库，然后返回。如果命中缓存，则更新缓存，然后由Cache自己更新数据库。
https://static001.geekbang.org/resource/image/93/9a/933ed3ddb7d56735a0db5101f86d9a9a.png?wh=902*1216

3. Write Behind Caching 更新模式
Write Behind又叫Write Back。在更新数据的时候，只更新缓存，不更新数据库，而缓存会异步地批量更新数据。好处是让数据的I/O操作飞快，异步还可以合并对同一个数据的多次操作。坏处是数据不是强一致性的，可能会丢失。
https://static001.geekbang.org/resource/image/6f/fd/6f7a59b05ddcb343f75ae2069b2a7efd.png?wh=1014*1292

### 缓存设计的重点

缓存已经成为高并发高性能架构的一个关键组件。很多公司都在用Redis搭建缓存系统。一方面是因为Redis的数据结构比较丰富，另一方面不能在Service内放Local Cache，一是每台机器的内存不够大，二是Service有多个实例，负载均衡器会把请求随机分布到不同的实例。所以在分布式架构下，一般需要一个外部的缓存集群。关于这个缓存集群，需要保证的是内存要足够大，网络带宽高，缓存本质上是个内存和IO密集型的应用。

内存大，还需要动用数据分片技术把不同的缓存分布到不同的机器上，保证缓存集群可以不断地scale下去。

缓存的命中率高说明缓存有效，一般说命中率到80%以上就算高，为了追求极高的性能要做到95%以上。但是通常热点数据只是少数。

缓存通过牺牲强一致性提高性能。

缓存数据的时间周期需要合理规划，可能导致应用程序不断从数据存储检索数据并将其添加到缓存，或是过期期限太长导致一些没人访问的数据还在内存中不过期浪费掉。

使用缓存一般使用LRU策略，当内存不够需要有数据被清出内存时，会找最不活跃的数据清除。开启LRU策略会让缓存在每个数据访问时把其调到前面，要淘汰数据时从最后面开始淘汰。对于LRU的缓存系统来说，需要在key-value这样的非顺序的数据结构中维护一个顺序的数据结构，并在读缓存时，改变被访问数据在顺序结构中的排位。于是LRU在读写时都需要加锁（除非是单线程无并发），LRU可能会导致更慢的缓存存取的时间。

需要建立爬虫保护机制。引导使用提供的外部API。同时，内部针对性地做多租户的缓存系统，把用户和第三方开发者的缓存系统分离开。

## 异步处理

异步通讯的设计模式有助于提高系统的稳定性和容错能力。异步通讯在分布式系统中还可以增加整个系统的吞吐量，从而可以面对更高的并发，并可以从容地利用好现有的系统资源。

### 异步处理的设计
1. 前台系统把用户发来的请求记录下来，操作在数据库或是存储上只有追加的操作，性能会很高。
2. 为了解耦，需要一个任务派发器，会出来推模型Push，一个是拉模型Pull。
3. 推拉结合，Push端会做一定的任务调度。然后Pull端来订阅Push端发出的异步消息，处理响应的任务。

### 事件溯源Event Sourcing
主要想解决的问题是，可以看到数据库中的一个数据的值（状态），但完全不知道这个值是怎么得来的。

如果代码里有Bug，在记录状态的系统里，修改bug后还需要做数据修正。然而在Event Sourcing的系统里，只需要把所有事件重新播放一遍，因为整个系统是无状态的。

事件不可变，并且可使用只追加操作进行存储。用户界面、工作流或启动事件的进程可继续，处理事件的任务可在后台异步运行。此外，处理事务期间不存在争用，这两点可极大提高应用程序的性能和可伸缩性。

事件是描述已发生操作的简单对象以及描述事件代表的操作所需要的相关数据。事件不会直接更新数据存储，只会对事件进行记录，以便在合适的时间进行处理。

事件溯源不需要直接更新数据存储中的对象，因而有助于防止并发更新造成冲突。

更重要的是，异步处理 + 事件溯源的方式，可以很好地让整个系统进行任务的统筹安排、批量处理，可以让整体处理过程达到性能和资源的最大化利用。

### 异步处理的分布式事务

要达到最终一致性，需要有个交易凭证。完成事务需要的注意点：
1. 凭证需要保存起来，不然会导致事务做不下去。
2. 凭证处理的幂等性问题，不然在重试时会出现多次交易的情况。
3. 事务完成不了，需要做补偿事务处理。

### 异步处理的设计要点

异步处理中的事件驱动和事件溯源是两个关键技术。

异步处理会因为一些故障导致任务没有被处理，如消息丢失，没有通知到，或通知到了没有处理。有这一系列的问题，异步通知的方式需要任务处理方处理完成后，给任务发起方回传状态。

发起方也需要有个定时任务，把一些超时没有回传状态的任务重新做一遍，可以认为这是异步系统中的对账功能。如果要重做的话，需要处理方支持幂等性处理。

异步处理的整体业务事务问题，也就是说，异步处理在处理任务的时候，并不知道能否处理成功，于是就会一步一步地处理，如果到最后一步不能成功。就需要回滚。走补偿事务的流程。并不是所有的业务都可以用异步的方式，需要强一致性的业务，使用异步的方式可能不适合。在需要性能的时候，需要牺牲强一致性，变为最终一致性。

在运维时，要监控任务队列里的任务积压情况。如果有任务积压，要能做到快速地扩容。如果不能扩容，而且任务积压太多，会导致整个系统挂掉，就要开始对前端流量进行限流。

异步处理系统的本质是把被动的任务处理变成主动的任务处理，本质是在对任务进行调度和统筹管理。

## 数据库扩展

### 读写分离CQRS
读写分离是数据库扩展最简单实用的做法，这种方法针对读多写少的业务场景管用，而且还可以有效地把业务做相应的隔离。

https://static001.geekbang.org/resource/image/27/a7/27ece98f96d18b6197f2184eb2c9c9a7.jpg?wh=1740x936

好处是：
- 比较容易实现。数据库的master-slave的配置和服务框架里的读写分离都比较成熟，应用起来也很快。
- 可以很好地把各个业务隔离开来。不会因为一个业务把数据库拖死而导致所有的业务都死掉。
- 可以很好地分担数据库的读负载，读操作是最耗数据库CPU的操作。

坏处是：
- 写库有单点故障问题。如果是写库出了性能问题，那么所有的业务一样不可用。对于交易型的业务，要得到高的写操作速度不太可行。
- 数据库同步不实时，需要强一致性的读写操作还是需要落在写库上。

CQRS全称Command and Query Responsibility Segregation，也就是命令与查询职责分离。原理是用户对于一个应用的操作可以分成两种，一种是Command也就是写操作（增，删，改），另一种是Query操作（查），也就是读操作。Query操作基本上是在做数据整合显现，而Command操作这边会有更重的业务逻辑。分离开这两种操作可以在语义上做好区分。
- 命令Command不会返回结果数据，只会返回执行状态，但会改变数据。
- 查询Query会返回结果数据，但是不会改变数据，对系统没有副作用。

分离开操作的好处：
- 分工明确，可以负责不同的部分。
- 将业务上的命令和查询的职责分离，能够提高系统的性能、可扩展性和安全性。并且在系统的演化中能够保持高度的灵活性，能够防止出现CRUD模式中，对查询或者修改中的某一方进行改动，导致另一方出现问题的情况。
- 逻辑清晰，能够看到系统中的哪些行为或者操作导致了系统的状态变化。
- 可以从数据驱动（Data-Driven）转到任务驱动（Task-Driven）以及事件驱动。

如果把Commnd操作变成Event Sourcing，那么只需要记录不可修改的事件，并通过回溯事件得到数据的状态。于是可以把写操作给完全简化掉，也变成无状态的，这样可以大幅度降低整个系统的副作用，并可以得到更大的并发和性能。

https://static001.geekbang.org/resource/image/ce/87/ceeb536d0fa15afa4f5fde0b2cbe7787.png?wh=831*339

### 分库分表 Sharding

一般来说影响数据库最大的性能问题有两个，一个是对数据库的操作，一个是数据库中数据的大小。

前者需要从业务上优化。一方面简化业务，不要在数据库上做太多的关联查询，而对于一些更为复杂的用于做报表或是搜索的数据库操作，应该把其移到更适合的地方。后者如果数据库里的数据越来越多，也会影响数据操作。而且对于分布式系统来说，后端服务都可以做成分布式的，而数据库最好也是可以拆开成分布式的。读写分离也因为数据库里的数据太多而变慢，分库分表就成了必须用的手段。

https://static001.geekbang.org/resource/image/a4/16/a457b93e2b76e41fec4fdac4b7e11616.jpg?wh=1506x1026

分库的策略：将数据库按某种规则分成多个库。

数据访问层：为了不让前面的服务感知到数据库的变化，需要引入一个叫“数据访问层”的中间件，用来做数据路由。但这个数据访问层的中间件不好写，要有解析SQL语句的能力，还要根据解析好的SQL语句来做路由。

为了避免数据访问层的麻烦，分片策略如下：
1. 按多租户的方式。用租户ID来分，这样可以把租户隔离开来。
2. 按数据的种类来分。
3. 通过范围来分。这样分片，可以保证在同一分片中的数据是连续的，于是数据库操作比如分页查询会更高效一些。
4. 通过哈希散列算法来分。此策略的目的是降低形成热点的可能性。但是会带来两个问题，一个就是前面说的跨库跨表的查询寻和事务问题，另一个就是如果要扩容需要重新哈希部分或全部数据。

上面是常见的分片模式，还需要考虑应用程序的业务要求及其数据使用模式。这里要注意几个非常关键的事宜：
1. 数据库分片必须考虑业务，从业务的角度入手，而不是技术的角度入手。
2. 只考虑业务分片，尽量不要走哈希散列的分片方式。

### 数据库扩展的设计重点

需要把数据库和应用服务一同拆开，一个服务一个库就是微服务的玩法，也是Amazon的服务化的玩法——服务之间只能通过服务接口通讯，不能通过访问对方的数据库。这样数据会被天然拆成服务化，而不是一个单体的库。在一个单体的库上做读写分离或是做分片都是一件治标不治本的事，真正治本的方法就是要和服务一起拆解。
当数据库也服务化后，才会在小的服务数据库上进行读写分离或分片的方式来获得更多的性能和吞吐量。这就是整个设计模式的原则————先做服务化拆分，再做分片。

分片的两种模式，一种是水平分片，一种是垂直分片。水平分片就是服务化拆分的分片方法。垂直分片是把一张表中的一些字段放到一张表中，另一些字段放到另一张表中。垂直分片主要把一些经常修改的数据和不经常修改的数据给分离开，这样在修改某个字段的数据时不会导致其它字段的数据被锁而影响性能。

Sharding更多是水平分片。注意事项：
1. 随着数据库中数据的变化，有可能现需要定期重新平衡分片，保证均匀分布并降低形成热点的可能性。重新平衡花费昂贵，若要减少重新平衡的频率，需要通过确保每个分片包含足够的可用空间来处理未来一段事件的变化。另外需要开发用于快速重新平衡分片的工具和脚本。
2. 分片是静态的，而数据的访问是不可预期的，可能需要经常性地调整分片，这样成本太高，所以最好使用一个索引表的方式来进行分片，也就是说把数据的索引动态地记录在一个索引表中。这样可以灵活地调度数据，当数据调度到另一台节点上时，只需要去索引表里改数据的位置就可以了。
3. 如果程序必须要从多个分片检索数据的查询，则可以使用并行任务从各个分片上提取数据，然后聚合到单个结果中。但是，此方法不可避免地会在一定程度上增加解决方案数据访问逻辑的复杂性。
4. 数据分片后，很难在分片之间保持引用完整性和一致性，也就是跨分片的事务，因此应尽量减少会影响多个分片中的数据的操作。如果应用程序必须跨分片修改数据，那么需要评估一致性以及评估是否采用两阶段提交的方式。
5. 配置和管理大量分片可能是一个挑战。在做相应的变更时，一定要先从生产线上拉出数据，然后根据数据计划好新的分片方式，并做好相当的测试工作。

## 秒杀

### 秒杀的流程
1. 前端页面要不断地向后端来请求。
2. 每次询问的时候，后端都会给前端一个时间，以校准前端的时间。
3. 后端服务器准备就绪，后端服务会返回一个URL。
4. 这个URL被安置在按钮上，可以点击。
5. 点击后，如果抢到库存，进入支付页面，没有则返回秒杀已结束。

### 秒杀的技术挑战
一方面是100万人同时请求，网络带宽不够；另一方面是理论上讲扛100万的TPS，需要非常多的机器。

最恐怖的是，所有的请求都会集中在同一条数据库记录上，无论怎么分库分表，还是使用分布式数据库效果有限，因为面对的是单条的热点数据。

### 秒杀的解决方案
在CDN上，100万个用户会被几十个甚至上百个CDN的边缘结点分担，于是能够扛得住。然后还需要在这些CDN结点上做文章。

一方面需要把小服务部署到CDN结点上，当前端页面确认是否开始的同时，还可以统计下多少人在线。每个小服务会把当前在线等待秒杀的人数隔一段时间就回传给数据中心，这样就知道全网总共在线的人有多少。

秒杀开始时，100万用户请求到的是CDN上的服务，这些服务按照0.02%的量把用户放到后面的数据中心，也就是1万个人放过去两个，剩下的9998都直接返回秒杀已结束。

## 边缘计算

1. 趋势上来说
整个计算机发展的本质就是人类生活信息化建设的过程。数量越来越大，分析结果的速度需要越来越快，这两个需求只会把我们逼到边缘计算上去。

2. 从从成本上讲
当需要处理的数据或是用户请求的规模越来越大，成本是呈现快速上升的曲线。

### 边缘计算的业务场景
边缘计算一定会成为必然产物，其会作为以数据中心为主的云计算的一个非常好的补充，可以做到下面一些事情：
1. 处理一些实时响应的业务。它和用户靠得很近，所以可以实时响应用户的一些本地请求。如某公司的人脸门禁系统、共享单车的开锁。
2. 处理一些简单的业务逻辑。比如像秒杀、抢红包这样的业务场景。
3. 收集并结构化数据。比如，把视频中的车牌信息抠出来，转成文字，传回数据中心。
4. 实时设备监控。主要是线下设备的数据采集和监控。
5. P2P的一些去中心化的应用。比如：边缘结点作为一个服务发现的服务器，可以让本地设备之间进行P2P通讯。
6. 云资源调度。边缘结点非常适合用来做云端服务的调度。比如，允许用户使用不同生产商的云存储服务，使用不同生产商但是功能相同的API服务（比如支付API相关）。因为是流量接入方，所以可以调度流量。
7. 云资源聚合。比如，我们可以把语音转文字的API和语义识别的API相结合，聚合出来一个识别语音语义的API，从而简化开发人员的开发成本。

### 边缘计算的关键技术
1. API Gateway。
2. Serveless/FaaS。服务函数化，这个技术就像是AWS Lambda服务一样，写好一个函数，然后不用关心这个函数运行在哪里，直接发布就好，然后就可以用了。

# 区块链

## 区块链技术的本质

### 区块链技术的革命性
1. 去中心化。
2. 数据防篡改。
3. 固定的发行量。

### 技术概要

去中心化的比特币交易处理流程
1. 需要交易的用户把交易传到网络中。
2. 网络上有些机器叫记账结点，它们通过比拼计算力的方式竞争记账权，这也叫“挖矿”。
3. 获得记账权的结点，会把待记账的交易进行计算打包，并向全网广播。收到新的记账包的结点会对其进行验证，验证通过后加入自己的区块。

“网络中的任何结点都是不能信任的，它们中的任何一个都可能会作恶”。

基于这个假设前提，这个分布式的账本系统需要有如下设计：任何人都可以拿到所有的数据。所以，数据要能很容易被验证是合法的没有被修改过的，而且也要是很难被人修改的。

基于这个设计，比特币使用了两个比较大的技术：“区块链技术”和“工作量证明共识机制”。

区块链：第一个技术就是区块链，区块链又叫blockchain，其中有一个一个的区块，每个区块中包含着一组交易信息，然后每个区块都会有一个ID（或是一个地址），这些区块通过记录前一个区块的ID来形成一条链。

https://static001.geekbang.org/resource/image/77/00/7794cf8d3e41046d3d3bf215c5edae00.png?wh=862*289

但是也有需要注意的地方：
1. 每个块的ID都是通过内容生成的，所以只要是内容有变化ID都会完全不一样。
2. 而生成ID的内容还包括上一个块的ID。于是只要上一个块的内容变了，ID也要跟着变，后面指向这个块的ID也要变。连锁效应会导致修改成本的提升。
3. 一处改处处改的方式，并不代表不能篡改，而只是让修改面比较大，让改动麻烦一点。
4. 旧的区块的篡改会造成大面积的修改，于是越旧的区块越不容易篡改，越安全。反之越新的区块越不安全。

真正让区块链做到非常难篡改的是工作量证明的共识机制。

### 工作量证明共识机制

一个公司内的分布式系统中的结点是被假设成可信任的，而在去中心化的网络下，结点要被假设成不可信任的。

几个与“数据一致性”相关的问题：
1. 没有服务器的去中心化的网络下，真理只是大多数人同意的东西。
2. “大多数人”的问题
3. 意见分歧问题

使用“极度消耗计算力”的方式提高成本，从而有效地遏制或解决下面几个问题：
1. 修改几乎变得不可能。
2. 掌握51%的算力的人变得几乎不可能。
3. 解决分歧。一方面，这么大的工作量找出来的区块ID，已经有效地降低了有意见冲突的概率。另一方面，就算同时出现多个区块，即区块链出现分支/分叉，也就是多个合法账本。而因为挖矿的成本太高，导致同时跟进多个账本不可能。

## 区块链技术细节：哈希算法

区块链像一个单向链表，一个数据块中保存着三个信息。
- 真正的数据。
- 自己的地址（或是ID）。
- 前一个数据块的地址。

https://static001.geekbang.org/resource/image/1c/62/1c75fed53ee023c353a31616d2b29e62.png?wh=864*210?wh=864*210

每一个数据块的地址的编码使用了计算机上的一个算法，叫做Secure Hash。Hash算法有几个功能：
1. 用来生成唯一标识一个数据块的ID（身份证），这个ID几乎不能重复。
2. 用来做数据的特征码。只要数据中一个bit的数据出现更改，整个hash值就完全不一样了。而且数学上保证，无法通过hash值反推回原数据。

### 比特币的hash算法
https://static001.geekbang.org/resource/image/a9/98/a99ad9de4d156cea9e8ee716c48e0298.png?wh=864*454

其中Version, Previous Block Hash, Merkle Root, Timestamp, Difficulty Target和Nonce这六个数据字段是区块链的区块数据协议头。后面的数据数交易数据，分别是本块中的交易笔数H和交易列表（最多不能超过1MB，中本聪制定）。

六个字段的含义：
1. Version：当前区块链协议的版本号，4个字节。升级后版本号会变。
2. Previous Block Hash：前面那个区块的hash地址。32个字节。
3. Merkle Root：这个字段可以简单理解为是后面交易信息的hash值。32个字节。
4. Timestamp：区块生成的时间。这个时间不能早于前面11个区块的中位时间，不能晚于“网络协调时间”————你所连接的所有结点时间的中位数。4个字节。
5. Bits：也就是上图中的Difficulty Target，表明当前的hash生成的难度。4个字节。
6. Nonce：一个随机值，用于找到满足某个条件的hash值。4个字节。

### 关于Merkle Root
可以简单地将Merkle Root理解为交易的hash值。

https://static001.geekbang.org/resource/image/ae/yy/aeee43cfda67490b4ee40daaf367acyy.jpg?wh=1989x1296

首先，比特币的每一笔交易会有三个字段，一个是转出方，一个是转入方，还有一个是金额。那么会对每个交易的这三个字段求hash，然后把交易的hash做两两合并，再求其hash，直到算出最后一个hash值。

交易分批Hash的好处：
1. 大量的交易数据可以被分成各种尺寸的小组，这样有利于整合数据和校验数据。
2. 这样的开销在存储和内存上并不大，然而可以提高校验一组数据的难易程度。
3. 在P2P的无中心化网络上，可以把大量数据拆成一个一个小数据片传输，可以提高网络的传输速度。

以太坊有三个不同的Merkle Root树。因为以太坊要玩智能合约，所以需要更多的Merkle Root。
1. 一个是用来做交易hash的Merkle Root。
2. 一个是用来表示状态state的。因为一个智能合同从初始状态走到最终状态需要有若干步，每一笔都会让合同的状态发生变化，所以需要保存合同的状态。
3. 一个是用来做交易收据的。主要是用来记录一个智能合约中最终发生的交易信息。

### 比特币的交易模型
比特币区块中的交易数据，其实也是一个链。为了讲清楚这个链，需要了解一下比特币交易中的两个术语，一个是input，一个是output，也就是交易的支出方（input）和收入方（output）。

在比特币中，一个交易可以有多个output，也就是说可以把一笔钱汇给多个人，但一个output只能对应一个源的input，还有一个条件是output跟input的总数要吻合。

UTXO（Unspent Transaction Output）因为没有账户和余额的概念，所以可以并行进行多笔交易。假设有多个UTXO，可以进行多笔交易不需要并行锁。然后其还有匿名性的特征，可以隐藏自己的交易目的地，而且没有余额意味着是没有状态的。知道有多少个比特币，只需要把UTXO的交易记录统计一下就可以知道。

## 区块链技术细节：加密和挖矿

比特币的加密：
1. 发起交易。从第一笔交易可以看到，A用自己的私钥为交易信息和自己的地址生成了交易的签名，然后把交易信息、自己的地址、交易签名和自己的公钥放出去，方便验证是由A发起的。
2. 验证交易。在验证时，使用A的公钥解密交易签名，得到交易的hash值。把交易信息和自己的地址做hash，确认和签名解密后的hash值一致。

一般的挖矿流程：
1. 从网络上取得之前的区块信息。
2. 从“待记账区”中获取一组交易数据（有优先级，比如成长时间、矿工小费等）。
3. 形成区块头（计算Merkle Root并设计记账时间Timestamp等）。
4. 开始穷举Nonce，来计算区块头的hash值。如果前面有18个零（小于Target），那么记账成功。如果没有从第一步重新开始。
5. 一旦某矿工成功打包一个区块，就会告诉其它矿工。收到消息的矿工会停下手上的动作，开始验证，验证通过后，广播给其他矿工。

## 区块链技术细节：去中心化的共识机制

### 分布式一致性算法

比特币的区块链网络在设计时使用的PoW（Proof of Work）算法思路。一个是限制一段时间内整个网络中出现提案的个数（增加提案成本），另外一个是放宽对最终一致性确认的需求，约定好大家都确认并沿着已知最长的链进行拓宽。也就是说，如果比特币在某一个时刻同时出现两个都合法的区块，那么两个都承认，于是区块链上会出现两个合法的分支。此时矿工可以选择任何一个分支继续，在某个分区的长度超过了另一个分支时，短的那个分支马上作废。

PoW和Paxos/Raft的算法在本质上的相同与不同。
1. 不同：
- 对于Paxos/Raft，需要Leader选举，而对于比特币或者以太坊这样的无中心化的方式是没有leader的。
- 对于Paxos/Raft，加入其网络（集群）的结点前提假设都是受信的。然而，对于比特币/以太坊来说，其前提假设都是不可信的，它们只相信超过一半的结点所同意的东西。
- 对于Paxos/Raft，需要事先对整个集群中的结点数有定义，而无中心化的比特币和以太坊中的结点是来去自由。如果Paxos/Raft在这样的环境下，随时进行伸缩难度较大。
2. 相同：
- 都是一致性的算法。
- 对系统的修改总是需要一个人来干（区块链用PoW消耗资源，让提案变得困难，Paxos/Raft用领导选举）。
- 系统中暂时的不一致是可以被修正的（区块链会考虑最长链，牺牲了强一致性，保证了可用性，Paxos/Raft如果没有超过半数的结点在线，会停止工作，牺牲可用性，保证强一致性）。

无论搞区块链还是分布式，都需要知道拜占庭容错系统研究中的三个重要理论：CAP、FLP、DLS。
- CAP理论。在网络发生阻断（Partition）时，只能选择数据的一致性（consistency）或可用性（availability），无法两者兼得。CAP理论和扩展性（scalibility）是无关的，在分片（sharded）或非分片的系统皆使用。
- FLP impossibility。在异步环境中，如果节点间的网络延迟没有上限，只要有一个恶意节点存在，就没有算法能够在有效的时间内达成共识。Las Vegas algorithms在每一轮皆有一定机率达成共识，随着时间增加，机率会越趋近于1。这也是许多成功的共识算法会采用的解决办法。
- 容错的上限。由DLS论文可知：
在部分同步（partially synchronous）的网络环境中（即网络延迟有一定的上限，但无法事先知道上限是多少），协议可以容忍最多1/3的拜占庭故障（Byzantine fault）。
在异步（asynchronous）网络环境中，具确定性质的协议无法容忍任何错误，但这篇论文并没有提及randomized algorithms在这种情况可以容忍最多1/3的拜占庭故障。
在同步（synchronous）网络环境中（网络延迟有上限且上限是已知的），协议可以容忍100%的拜占庭故障。但当超过1/2的节点为恶意节点时，会有一些限制条件。但考虑的是具认证特性的拜占庭模型（authenticated Byzantine），而不是一般的拜占庭模型。具认证特性指的是将如今已经过大量研究且成本低廉的公私钥加密机制应用在我们的算法中。

### 工作量证明
Proof-of-Work，简称PoW，工作量证明。我们用这种消耗对手能源的手段来阻止一些恶意的攻击或是像垃圾邮件这样的对服务的滥用。

PoW的两种协议：
1. Challenge-Response协议，用于Client-Server。如果Client需要使用服务，那么需要被Challenge去花费一些资源。如果证明自己的资源已被花费了，则通过认证，授权使用。
https://static001.geekbang.org/resource/image/51/94/51b22e1076f3db3d4e8063f382f09894.png?wh=766*208
2. Solution-Verfication协议，用于验证使用。Hashcash就是这种协议。
https://static001.geekbang.org/resource/image/32/e8/32dbf07ce5ef0333333a1cc563b2b2e8.png?wh=750*206

Pow的初衷是通过消耗资源的方式阻止恶意攻击，然而在区块链的去中心化的世界里，PoW还有另一个功能，那就是让这些不受控制的分布式P2P网络里的结点统一思想，就是分布式一致性。

工作量证明是为了以下几件事：
1. 提高对数据篡改的成本。使修改数据需要付出大量的算力，而区块链的数据相互依赖，导致一处改处处改，要完全修改需要花费大量的算力。
2. 提高网络中有不同声音的成本。增加伪造账本的成本，减少校验账本的成本。
3. 解决分歧。让整个去中心化系统的一致性，不再以人数多认可的数据为准，而是以算力多的人认可的数据为准。

PoW当下问题：
1. 越来越中心化地记账。
2. 验证数据是否正确的成本变高，个人电脑无法运行。

### 股权证明协议
为了每个Block更快生成，出现了PoS（Proof of Stake）协议，中文翻译为股权证明协议。

PoS机制下，矿工不叫矿工，而是叫Validator（校验者），每个Validator需要以交押金的方式获得记账权，记账后没有奖金，只有手续费。

PoS机制下，记账权不再像PoW那样由谁的算力大谁就有机会来记账，而是由谁的财富多，谁就越有可能来记账，于是记账权按大家财富的比例来分配。PoW像是多劳多得的社会，而PoS更像是资本主义社会，钱越多的人越有话语权。博弈论的角度上讲，钱越多的人越有动力维护社会的稳定，因为如果社会不稳定，他是损失最为惨重的人。

PoS几个好处：
1. 不用再那么费劲挖矿。
2. 在P2P这种无中心化的网络下，如果要控制整个网络，需要半数以上的能力。

潜在问题：
1. 不需要太多算力的时候，如果账本出现分叉的情况，也就是系统出现两个冲突且合法的区块时，在比特币这种算力密集的PoW机制下，所有矿工必须赌其中一个分支往下走。
2. 在PoS这种不需要算力的机制下，可以让记账人在两个分支上同时进行，以争取实现利益的最大化。这样一来，攻击者可以利用这种情况来发起Nothin-At-Stake攻击。
3. 发起贿赂攻击（Bribe Attack）攻击者可以在一个分支上声称购买了某个商品，然后收到货后，以提高手续费的方式只养另一个没有购买这个商品交易的分支，然后把没有这个交易的链养得足够长，长到系统最终选择没有交易的这条链。

### DPoS机制
在常规PoW和PoS中，一大影响效率之处在于任何一个新加入的区块，都需要被整个网络所有节点做确认。DPoS优化方案在于：通过不同的策略，不定时地选中一小群节点，这一小群节点做新区块的创建、验证、签名和相互监督。这样大幅度减少区块创建和确认所需要消耗的时间和算力成本。

EOS推崇DPoS，但存在以下隐患：
1. DPoS已经开始把区块链的去中心化的初衷开始向中心化的地方演进。
2. 政治在未来区块链的世界里必不可少，意味着不可控的复杂性。

### 小结
分布式的CAP原则，在一致性、可用性、分区容忍性只能三选二。在区块链的P2P网络也是类似，在去中心化、安全和高性能中，只能选两个。

https://static001.geekbang.org/resource/image/6f/c2/6fb02bab3d6a1a92429f7a2a73b9ebc2.jpg?wh=1005x786

如果想要一个既安全，性能也很高的系统，那么得放弃去中心化的架构，如DPoS这样的中心化系统，直接放弃区块链走传统的中心化架构。
如果想要一个去中心化和安全的系统，主要去挖矿，那么放弃高性能。这就是目前的比特币架构。
如果想要一个去中心化和高性能的系统，就得放弃安全。没有安全的系统，基本上没有人会使用。

## 区块链技术细节：智能合约

## 传统金融和虚拟货币

### 金融的本质
促进交易完成，实现价值提升。

为了保证交易完成，金融行业需要解决下面几个问题：
1. 交易中的信用问题。所以银行会来做中间人来担保。
2. 交易中资金不足的问题。通过借贷来让交易完成。
3. 交易中大额的问题。把一个大额的金融事件以股份的方式拆碎进行大众投资。

金融行业的四个重要属性：
1. 效率提升：加快货币、股票、债券的流通性，快速地促进交易。
2. 价值提升：通过金融产品的流通性，让实际价值得到充分的体现，并升值。
3. 激励机制：为实体经济添砖加瓦，并激励社会持续付出和成长。
4. 信用评级：建立信用社会、评估信用等级，从而改善社会。

### 经济运作的原理

经济其实就是整个社会的交易。每个交易中，对于买方，需要付出的是货币和信用，对于卖方，需要付出的是商品、服务或金融资产。一个社会最基本的经济活动是交易，而经济情况的好坏是受受支出方影响的。支出是经济的原动力。

经济的价值是可能通过提高“生产率”来提高的。然而，生产率并不是很容易能提高的，这是一个长期的过程。而通过“借贷”我们可以短期地提高经济价值，在借贷发生时，消费超过产出，在还贷时，消费低于产出。

如果整个社会的支出变多，那就会出现一片繁荣的情况。大多数人都是目光短浅的，他们可能会觉得经济形势很好，于是就出现更多的借贷。人们觉得挣钱好容易，于是就借钱来买其他金融产品，导致金融产品上涨，紧接着进一步导致大家觉得应该花更多的钱来投资，那样就会借更多的钱。如此一来，出现巨大泡沫。

### 虚拟货币

虚拟货币想要有货币的特征，那么就需要保持稳定。但虚拟货币没有一个经济体为其背书，远远达不到货币的功能。

现在区块链里的经济，是靠二级市场支撑。

当前存在的几个问题：
1. 交易成本上升。
2. 个人无法参与。
3. 社区的利益纷争。

功能问题：
1. 交易时的身份认证。虚拟代币只关心私钥，而不关心是不是本人。
2. 资金归属权保护。虚拟代币如果密码和私钥丢失，就真的丢了。
3. 损失赔偿问题。

逻辑问题：
1. 技术驾驭能力。
2. 比特币颠覆了什么？
3. 是否消除了中间商？
4. 大公司参与的区块链？
5. 投资人投资去中心化的公司？
6. 传销组织的三个阶段：
- 让你觉得你很穷困，告诉你致富的捷径。
- 模糊具体细节，用高大上的类比和比喻来取得对方信任。
- 通过发展下线来制造虚假繁荣。

# 高效学习

## 端正学习态度

学习是一件逆人性的事情，需要人持续付出，会让人感到痛苦，并随时想找理由放弃。

### 主动学习和被动学习

https://static001.geekbang.org/resource/image/e4/16/e46f9dc2d0bc9e5f62ab688e1675b616.png?wh=745*612
被动学习：
如听讲、阅读、视听、演示，学习内容的平均留存率为5%、10%、20%和30%。
主动学习：
如通过讨论、实践、教授给他人，会将原来被动学习的内容留存率从5%提升到50%、75%和90%。

学习不是努力读更多的书，盲目追求阅读的速度和数量，这会让人产生低层次的勤奋和成长的感觉，这只是在使蛮力。要思辨，要践行，要总结和归纳，否则只是在机械地重复某件事，而不会有质的成长的。

### 浅度学习和深度学习

当前社会：
1. 大多数人的信息渠道都被微信朋友圈、微博、知乎、今日头条、抖音占据着。这些信息渠道中有营养的信息少之又少。
2. 大多数公司都是实行类似于996这样的加班文化，在透支和消耗下一代年轻人，让他们成长不起来。
3. 因为国内互联网访问不通畅，加上英文水平受限，所以大多数人根本没办法获取到国外的第一手信息。
4. 快餐文化盛行，绝大多数人都急于速成，心态比较浮躁，对事物不求甚解。

如何进行深度学习：
1. 高质量的信息源和第一手的知识。
2. 把知识连成地图，将自己的理解反述起来。
3. 不断地反思和思辨，与不同年龄段的人讨论。
4. 举一反三，并践行之，把知识转换成技能。

学习的三个步骤：
1. 知识采集。信息源是非常重要的，获取信息源头、破解表面信息的内在本质、多方数据印证，是这个步骤的关键。
2. 知识缝合。所谓缝合就是把信息组织起来，成为结构体的知识。这里，连接记忆，逻辑推理，知识梳理是很重要的三部分。
3. 技能转换。通过举一反三、实践和练习，以及传授指导，把知识转化成自己的技能。这种技能可以让人进入更高的阶层。

### 学习是为了找到方法

学习不仅仅是为了找到答案，而更是为了找到方法。

只有掌握解题的思路，才算得上拥有解决问题的能力。

学习是为了找到通往答案的路径和方法，是为了拥有无师自通的能力。

### 学习是为了找到原理

学习不仅仅是为了知道，而更是为了思考和理解。在学习的过程中，我们不是为了知道某个事的表面是什么，而是要通过表象去探索其内在的本质和原理。真正的学习，从来都不是很轻松的，而是那种知道得越多，问题就会越多，问题越多，就会思考得更多，思考得更多，就会越觉得自己知道的越少，于是就会想要了解更多。

这些问题都会驱使人像一个侦探一样去探索背后的事实和真相，并在不断的思考中一点一点地理解整个事情的内在本质、逻辑和原理。一旦理解和掌握了这些本质的东西，就会发现，整个复杂多变的世界在变得越来越简单。就好像找到了所有问题的最终答案似的，一通百通了。

### 学习是为了了解自己

学习不仅仅是为了开拓眼界，而更是为了找到自己的未知，为了了解自己。 

开拓眼界的目的就是发现自己的不足和上升空间，从而才能让自己成长。

### 学习是为了改变自己

学习不仅仅是为了成长，而更是为了改变自己。

只有做出了改变，我们才能够获得更好的成长。质的成长，源于突然间开窍，开始用一种更有效率、更科学、更系统的方式做事，然后达到更高的地方。

学习是为了改变自己的思考方式，改变自己的思维方式，改变自己与生俱来的那些垃圾和低效的算法。总之，学习让我们改变自己，行动和践行，反思和改善，从而获得成长。

## 源头、原理和知识地图

### 挑选知识和信息源

信息源要有以下几个特质：
1. 应该是第一手资料，不是被别人理解过、消化过的二手资料，尤其对于知识性的东西来说，更是这样的，应该是原汁原味，不应该是被添油加醋的。
2. 应该是有佐证、有数据、有引用的，或是有权威人士或大公司生产系统背书的资料。应该是被时间和实践检验过的，或是小心求证过的，不是拍脑袋野路子或是道听途说出来的资料。
3. 应该是加入了一些自己的经验和思考，可以引发人深思的，是所谓信息的密集很大的文章。

### 注重基础和原理

基础知识和原理性的东西和技术，都是经历过长时间的考验的，所以这些基础技术也有很多人类历史上的智慧结晶，会给人很多启示和帮助。

### 使用知识图

从知识树的主干开始做广度或是深度遍历，于是就得到了一整棵的知识树。最重要的是，当出现一些不知道的知识点时，就会往这棵知识树上挂，这样一来，可以让学习更为系统和全面。

画知识图的方式可以让技术最重要最主干的地方出发开始遍历所有的技术细节，也就是画地图的方式。学习并不是为了要记忆那些知识点，而是为了要找到一个知识的地图，你在这个地图上能通过关键路径找到想要的答案。

## 深度、归纳和坚持实践

### 系统地学习

系统学习的模板：
1. 这个技术出现的背景、初衷和要达到什么样的目标或是要解决什么样的问题。
2. 这个技术的优势和劣势分别是什么，或者说，这个技术的trade-off是什么。
3. 这个技术适用的场景。一个是业务场景，一个是技术场景。
4. 技术的组成部分和关键点。
5. 技术的底层原理和关键实现。
6. 已有的实现和它之间的对比。

### 举一反三

举一反三能力的分解：
1. 联想能力。同一个事物的不同的用法。
2. 抽象能力。
3. 自省能力。

对自己的训练：
1. 对于一个场景，制造出各种不同的问题或难题。
2. 对于一个问题。努力寻找尽可能多的解，并比较这些解的优劣。
3. 对于一个解，努力寻找各种不同的测试案例，以图让其健壮。

### 总结和归纳

对自己的知识进行总结和归纳是提高学习能力的一个非常重要的手段。把学到的东西用自己的语言和理解重新组织并表达出来。本质上是对信息进行消化和再加工的过程，这个过程可能会有信息损失，但也可能会有新信息加入，本质上是信息重构的过程。

我们积累的知识越多，在知识间进行联系和区辨的能力就越强，对知识进行总结和归纳也就越轻松。想要提高总结归纳的能力，首先要多阅读，多积累素材，扩大自己的知识面，多和别人讨论，多思辨，从而见多识广。

如果只学了部分知识或者还没学透，就开始对知识进行总结归纳，那么总结归纳出来的知识结构也只能是混乱和幼稚的。因此，学习的开始阶段，可以不急于总结归纳，不急于下判断，做结论，而应该保留部分知识的不确定性，保持对知识的开放状态。当对整个知识的理解更深入，自己站的位置更高以后，总结和归纳才会更有条理。总结归纳更多是在复习中对知识的回顾和重组，而不是一边学习一边就总结归纳。

做总结归纳的方法：把看到和学习到的信息，规整好，关联好，把信息碎片给结构化掉，然后在结构化的信息中，找到规律，找到相通之处，找到共同之处，进行简化、归纳和总结，最终形成一种套路，一种模式，一种通用方法。

### 实践出真知

### 坚持不懈

坚持也不是要苦苦地坚持，有循环有成就感的坚持才是真正可以持续的。一方面要把坚持形成成果晒出来，让别人来点赞。另一方面，还要把坚持变成一种习惯，感觉不到太多的成本付出。

## 如何学习和阅读代码

### 读文档还是读代码

代码 => What, How & Details
文档/书 => What, How & Why

书和文档是人对人说的话，代码是人对机器说的话。所以：
1. 如果想知道人为什么要这么搞，那么应该去看书，看文档。
2. 如果要知道让机器干了什么？那么应该看代码。

实现的目的：
1. 如果想了解一种思想，一种方法，一种原理，一种思路，一种经验，读书和读文档会更有效率一些。
2. 如果想了解的就是具体细节，比如某协程的实现，某个模块的性能，某个算法的实现，那么还是要去读代码的，代码中会有更具体的处理细节。

人对新事物的学习过程都是从感性认识到理性认识的：
1. 如果是个新手，应该多读代码，多动手写代码。在新手阶段，会喜欢GitHub这样的东西。
2. 如果是个老手，这个阶段，会喜欢读好的书和文章。

### 如何阅读源代码

阅读代码之前的前提：
1. 基础知识。相关的语言和基础技术的知识。
2. 软件功能。先要知道这个软件完成的是什么样的功能，有哪些特性，哪些配置项。要先读一遍用户手册，让软件跑起来。
3. 相关文档。读相关的内部文档，Readme，Release Notes，Design，Wiki都可以。
4. 代码的组织结构。也就是代码目录中每个目录是什么样的功能，每个文档是干什么的。

了解软件的代码是由哪些部分构成的：
1. 接口抽象定义。
2. 模块粘合层。如中间件（middleware）、Promises模式、回调（Callback）、代理委托、依赖注入等。
3. 业务流程。一般需要画程序流程图或者时序处理图。
4. 具体实现。
- 代码逻辑。一种是业务逻辑，这种逻辑是真正的业务处理逻辑；另一种是控制逻辑，这种逻辑只是用控制程序流转的，不是业务逻辑。
- 出错处理。二八原则，两成代码是正常的逻辑，八成代码是在处理各种错误。
- 数据处理。
- 重要的算法。往往是最有技术含量的部分。
- 底层交互。代码和底层系统的交互。
5. 运行时调试。

阅读代码的方法：
1. 一般采用自顶向下，从总体到细节的读法。
2. 画图是必要的，程序流程图，调用时序图，模块组织图。
3. 代码逻辑归类，排除杂音，主要逻辑才会更清楚。
4. debug跟踪一下代码是了解代码在执行中发生了什么的最好方式。

source insight

## 如何面对枯燥和大量的知识

### 如何面对枯燥的知识

1. 知识太高级，不知道用在什么地方。
2. 人的认知是从感性认识到理性认识转化的，所以，可能要先去找一下应用场景，学点更实用的，再回来学理论。
3. 学习需要有反馈，有成就感，带着相关问题去学习会更好。
4. 找到牛人来讲解。

### 如何面对大量的知识

带着问题去学习，带着要解决的东西去学习，带着挑战去学习，于是每当解决了一个问题，做了一个功能，完成了一个挑战，就会感到兴奋和有成就感，这样就找到了源源不断的学习驱动力。

### 认真读文档

### 其他实用的技巧

1. 用不同的方式来学习同一个东西。
2. 不要被打断。
3. 总结压缩信息，只关心关键点。
4. 把未知关联到已知。
5. 用教的方式来学习。
6. 学以致用。
7. 不要记忆。
8. 多犯错误。但是不要犯低级错误。

# 高效沟通

## Talk和Code同等重要

有效的沟通是事业成功的必要条件。

### 沟通的原理和问题

通过一些约定简化沟通成本。

反馈也是很好的方式。

秉持的原则：
将信息源头的信息原模原样分享出去。

## 沟通阻碍和应对方法

### 信息不准确

在沟通之前，首先要想清楚沟通的目的是什么，然后整理自己的措辞。如果是一些比较重要的沟通，最好可以把自己的想法写下来，然后放一会儿，再回过头来想，想象一下如果是别人对自己讲这些话，自己会怎么理解。

当别人没有表达清楚的时候，要及时打断对方，跟对方说没有听懂，不知道是什么意思，是否可以重新澄清一下。如果明明知道不懂却不好意思问，这就是沟通中最大的阻碍，沟通就是要来来回回的确认。

沟通效率的关键不在于快，而是准确。

### 信息太多

不要绕弯子，有话直说，这是最高效的沟通方式。这既是对对方的一种信任，也是一种对自己的尊重。这样的沟通，事情往往能得到更好的解决。

### 没有交互

找到对方的兴趣点，降低表达自己真实想法的门槛，培养让大家畅所欲言的自由环境，把自己的答案变成问题，让其他人有参与感，这样才可能有好的沟通，也能够有好的结果。

### 表达方式

沟通中有两个非常重要的因素，一是沟通的内容，二就是表达方式和态度。

很多时候沟通失败，不是沟通内容出了问题，是表达方式、谈话的态度出了问题。

### 二手信息

到信息的源头，向当事人去求证，会让这个世界更加和谐，也会让人更有智慧。

### 信道被黑

让信息公开透明，将没有处理过的信息，完整一致地传递给别人。

## 沟通方式及技巧

### 沟通方式

1. 尊重
- 我可以不同意你，但是会捍卫你说话的权利。
- 赢得对方的尊重需要先尊重对方。
尊重一定要和对方有观点上的交互，甚至是碰撞。沟通的目的不是为了附和对方，而是产生一种更完整更全面的认知。

2. 倾听
《沟通的艺术》，倾听与听或者听到有很大的不同，它是解读别人所说信息的过程，包含听到、专注、理解、回应和记忆五大元素。

3. 情绪控制
- 不要过早或者过度打岔和反驳。
- 求同存异，冷静客观。切莫在冲动之下，说出很多一些过分或过激的话，因为语言的力量是巨大的，杀伤力有时难以预估。

### 沟通技巧

1. 引起对方的兴趣
利益，勾起对方的兴趣。

2. 直达主题，强化观点。
确定自己的目标，学会抓重点，知道自己要什么和不要什么，这样要的才会更鲜明。当一些事情变得简明和鲜明起来时，才会表现出有力量的观点和话语。

3. 基于数据和事实。数据、事实、证据和权威是沟通中的要点。

## 沟通技术

逻辑、信息、维度、共同

高纬度容易拉拢对方，而在低纬度更容易说服对方。只不过低维度容易爆发冲突。

### 推荐书籍

无论干什么，一定要有一个非常犀利的观点，也就是金句。

《清醒思考的艺术》、《简单的逻辑学》、《重来》

## 好老板要善于提问

引导，用提问的方式，“倒逼”员工找到答案，从而提高员工的参与感和成就感。

倾听，心态平和，毫无偏见，全面接收和理解对方的信息，而不是只听自己想听的信息。

共情，换位思考，站在对方立场设身处地思考和处理问题，动之以情，晓之以理。

高维，提升自己的格局观，能从全局利益、长远利益思考问题，解决问题。

反馈，建立反馈机制，及时发现问题、解决问题，形成正向循环。

## 好好说话的艺术

### 跟员工沟通

1. 一对一会议
好的一对一会议是以员工为中心，而不是以管理者为中心。一对一会议时，管理者需要做的是倾听，而非喋喋不休地教育。

会议重点：
- 工作状态。这个环节主要了解影响员工状态地细节，为员工进行疏导、激励和优化，并和员工一起对过去几周地工作做出得失总结，一起进步。
- 个人发展，员工地个人发展是员工和公司的头等大事，需要了解员工的兴趣、爱好、擅长做的事，以及缺点和不足，并结合公司的目标和实际项目需求，为员工创造更有挑战的工作，让员工更好地成长。
- 公司组织，让员工聊聊对公司的看法，公司做的好/没做好的地方，有哪些可以改进的建议。目的是了解员工是否认可公司的目标和方向。
- Leader自己。请员工聊聊对自己的看法。放平心态，不管是好的还是坏的，都用平常心对待。如果被员工指出哪里有不足，可以请员工给自己一些建议，或者请他来谈谈他认为怎样做会比较好。

一对一会议的时间通常为半个小时到一个小时，时间不要太长。一对一会议中，核心沟通原则是将心比心。其中的诀窍是让员工畅所欲言，不要有任何的忌讳，能够讲出最真实的想法。

2. 绩效沟通
沟通一定要放在平时，不要搞成球后算账一样！因为是管理者，不是地主监工。

反馈的过程中，不是在指责员工，而是在帮助员工。一定要有帮扶的态度，这样员工会更容易接受。

3. 独立特性的员工

一是给他找到匹配的人，要么是比他牛，要么是跟他旗鼓相当可以在一起共事的人。二是给他一些独立的工作，把他隔离出去，让他做一些相对独立和有挑战的事情。

在一个人身上花的精力和时间成本，大于到外面找一个更好的人或者能力相当的人来替代他时，就要坚决地把他替换掉。

4. 挽留离职员工

首先，要知道他离职的原因。

生意不行友情在。既然不能在此时挽留下来，那就放眼未来，能在一起工作的机会还有很多。要提前判断员工离职的前兆。最终摊牌的时候，或者对公司漠不关心，留下来的机会是很小的。

5. 劝退员工

任何人都应该有可以纠正错误的机会，公司应该给员工这样的机会，员工也应该给公司同样的机会。

### 跟客户沟通

1. 吸引客户的兴趣

2. 帮客户发现问题
- 结合客户的痛点，了解客户做过的尝试。
- 深入细节，了解细节才会有更准确的信息。
- 小心X/Y问题，找到X问题。一定要分析客户问题背后的本质原因，从根本上帮助客户解决问题。

3. 管理客户的期望

如果做到既让客户满意，又不会作茧自缚：
- 要啊至少给出三套方案来让客户选择，一个是低成本的玩法，一个是高成本的玩法，一个是性价比比较高的玩法，这其中的取舍是可以去引导客户的。
- 需要找一些相关的案例和参照物来对比给的上述方案，这样可以让客户有一个更为清醒的判断和认识。以此来教育客户不同的方案代表着不同的期望和不同的结果。

永远不要跟客户说不，要有条件地说是，告诉客户不同的期望要有不同的付出和不同的成本。不要帮客户做决定，而是给客户提供尽可能多的选项，让客户来决定。

讨价还价是这个世界能运转的原因之一，要学会使用。在与客户沟通预期时，通常会坚持以下几个原则。
- 一定要给客户选择权，永远不要说不，要有条件地说是。
- 降低期望的同时给与其他的补偿。
- 提高期望的同时附加更多的条件。
- 对于比较大的期望要分步骤达到客户的期望。
- 不要帮客户做决定，而是给客户提供尽可能多的选项，然后引导客户做决定。

### 跟老板沟通

1. 了解你的老板

了解老板的做事风格。

了解老板的目标和KPI是什么。

要知道老板的老板是谁，他的风格是什么，他的目标和KPI是什么。

了解老板背后的苦衷。

2. 赢得老板的信任

3. 管理老板的期望

4. 非暴力“怼老板”

要让老板觉得欠人情